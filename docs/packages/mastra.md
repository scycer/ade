# Mastra

> Mastra is an open-source TypeScript agent framework designed to provide the essential primitives for building AI applications. It enables developers to create AI agents with memory and tool-calling capabilities, implement deterministic LLM workflows, and leverage RAG for knowledge integration. With features like model routing, workflow graphs, and automated evals, Mastra provides a complete toolkit for developing, testing, and deploying AI applications.

This documentation covers everything from getting started to advanced features, APIs, and best practices for working with Mastra's agent-based architecture.

The documentation is organized into key sections:
- **docs**: Core documentation covering concepts, features, and implementation details
- **examples**: Practical examples and use cases demonstrating Mastra's capabilities
- **showcase**: A showcase of applications built using Mastra

Each section contains detailed markdown files that provide comprehensive information about Mastra's features and how to use them effectively.


## EN - docs
- [adding-voice](https://mastra.ai/en/docs/agents/adding-voice)
- [Using Agent Memory | Agents | Mastra Docs](https://mastra.ai/en/docs/agents/agent-memory): Documentation on how agents in Mastra use memory to store conversation history and contextual information.
- [Dynamic Agents](https://mastra.ai/en/docs/agents/dynamic-agents): Dynamically configure your agents instruction, model, tools, and memory using runtime context.
- [Input Processors](https://mastra.ai/en/docs/agents/input-processors): Learn how to use input processors to intercept and modify agent messages before they reach the language model.
- [Output Processors](https://mastra.ai/en/docs/agents/output-processors): Learn how to use output processors to intercept and modify AI responses before they are returned to users.
- [Agent Overview | Agent Documentation | Mastra](https://mastra.ai/en/docs/agents/overview): Overview of agents in Mastra, detailing their capabilities and how they interact with tools, workflows, and external systems.
- [Runtime context | Agents | Mastra Docs](https://mastra.ai/en/docs/agents/runtime-variables): Learn how to use Mastras dependency injection system to provide runtime configuration to agents and tools.
- [Using Tools with Agents | Agents | Mastra Docs](https://mastra.ai/en/docs/agents/using-tools-and-mcp): Learn how to create tools, add them to Mastra agents, and integrate tools from MCP servers.
- [Auth Overview](https://mastra.ai/en/docs/auth): Learn about different Auth options for your Mastra applications
- [MastraJwtAuth](https://mastra.ai/en/docs/auth/jwt): Documentation for the MastraJwtAuth class, which authenticates Mastra applications using JSON Web Tokens.
- [Contributing Templates](https://mastra.ai/en/docs/community/contributing-templates): How to contribute your own templates to the Mastra ecosystem
- [Discord Community and Bot | Documentation | Mastra](https://mastra.ai/en/docs/community/discord): Information about the Mastra Discord community and MCP bot.
- [Licensing](https://mastra.ai/en/docs/community/licensing): Mastra License
- [Amazon EC2](https://mastra.ai/en/docs/deployment/cloud-providers/amazon-ec2): Deploy your Mastra applications to Amazon EC2.
- [AWS Lambda](https://mastra.ai/en/docs/deployment/cloud-providers/aws-lambda): Deploy your Mastra applications to AWS Lambda using Docker containers and the AWS Lambda Web Adapter.
- [Azure App Services](https://mastra.ai/en/docs/deployment/cloud-providers/azure-app-services): Deploy your Mastra applications to Azure App Services.
- [Digital Ocean](https://mastra.ai/en/docs/deployment/cloud-providers/digital-ocean): Deploy your Mastra applications to Digital Ocean.
- [Cloud Providers](https://mastra.ai/en/docs/deployment/cloud-providers): Deploy your Mastra applications to popular cloud providers.
- [Monorepo Deployment](https://mastra.ai/en/docs/deployment/monorepo): Learn how to deploy Mastra applications that are part of a monorepo setup
- [Deployment Overview](https://mastra.ai/en/docs/deployment/overview): Learn about different deployment options for your Mastra applications
- [Deploy a Mastra Server](https://mastra.ai/en/docs/deployment/server-deployment): Learn how to deploy a Mastra server with build settings and deployment options.
- [Cloudflare Deployer](https://mastra.ai/en/docs/deployment/serverless-platforms/cloudflare-deployer): Learn how to deploy a Mastra application to Cloudflare using the Mastra CloudflareDeployer
- [Serverless Deployment](https://mastra.ai/en/docs/deployment/serverless-platforms): Build and deploy Mastra applications using platform-specific deployers or standard HTTP servers
- [Netlify Deployer](https://mastra.ai/en/docs/deployment/serverless-platforms/netlify-deployer): Learn how to deploy a Mastra application to Netlify using the Mastra NetlifyDeployer
- [Vercel Deployer](https://mastra.ai/en/docs/deployment/serverless-platforms/vercel-deployer): Learn how to deploy a Mastra application to Vercel using the Mastra VercelDeployer
- [Deploying Mastra with a Web Framework](https://mastra.ai/en/docs/deployment/web-framework): Learn how Mastra can be deployed when integrated with a Web Framework
- [Create a custom eval](https://mastra.ai/en/docs/evals/custom-eval): Mastra allows you to create your own evals, here is how.
- [Overview](https://mastra.ai/en/docs/evals/overview): Understanding how to evaluate and measure AI agent quality using Mastra evals.
- [Running in CI](https://mastra.ai/en/docs/evals/running-in-ci): Learn how to run Mastra evals in your CI/CD pipeline to monitor agent quality over time.
- [Textual Evals](https://mastra.ai/en/docs/evals/textual-evals): Understand how Mastra uses LLM-as-judge methodology to evaluate text quality.
- [Using with Vercel AI SDK](https://mastra.ai/en/docs/frameworks/agentic-uis/ai-sdk): Learn how Mastra leverages the Vercel AI SDK library and how you can leverage it further with Mastra
- [Using with Assistant UI](https://mastra.ai/en/docs/frameworks/agentic-uis/assistant-ui): Learn how to integrate Assistant UI with Mastra
- [Using with CopilotKit](https://mastra.ai/en/docs/frameworks/agentic-uis/copilotkit): Learn how Mastra leverages the CopilotKits AGUI library and how you can leverage it to build user experiences
- [Using with OpenRouter](https://mastra.ai/en/docs/frameworks/agentic-uis/openrouter): Learn how to integrate OpenRouter with Mastra
- [Getting started with Mastra and Express | Mastra Guides](https://mastra.ai/en/docs/frameworks/servers/express): A step-by-step guide to integrating Mastra with an Express backend.
- [Getting Started with Mastra and Astro | Mastra Guides](https://mastra.ai/en/docs/frameworks/web-frameworks/astro): A step-by-step guide to integrating Mastra with Astro.
- [Getting Started with Mastra and Next.js | Mastra Guides](https://mastra.ai/en/docs/frameworks/web-frameworks/next-js): A step-by-step guide to integrating Mastra with Next.js.
- [Getting Started with Mastra and SvelteKit | Mastra Guides](https://mastra.ai/en/docs/frameworks/web-frameworks/sveltekit): A step-by-step guide to integrating Mastra with SvelteKit.
- [Getting Started with Mastra and Vite/React | Mastra Guides](https://mastra.ai/en/docs/frameworks/web-frameworks/vite-react): A step-by-step guide to integrating Mastra with Vite and React.
- [Installing Mastra | Getting Started | Mastra Docs](https://mastra.ai/en/docs/getting-started/installation): Guide on installing Mastra and setting up the necessary prerequisites for running it with various LLM providers.
- [Using with Cursor/Windsurf | Getting Started | Mastra Docs](https://mastra.ai/en/docs/getting-started/mcp-docs-server): Learn how to use the Mastra MCP documentation server in your IDE to turn it into an agentic Mastra expert.
- [model-capability](https://mastra.ai/en/docs/getting-started/model-capability)
- [Model Providers | Getting Started | Mastra Docs](https://mastra.ai/en/docs/getting-started/model-providers): Learn how to configure and use different model providers with Mastra.
- [Local Project Structure | Getting Started | Mastra Docs](https://mastra.ai/en/docs/getting-started/project-structure): Guide on organizing folders and files in Mastra, including best practices and recommended structures.
- [Templates | Getting Started | Mastra Docs](https://mastra.ai/en/docs/getting-started/templates): Pre-built project structures that demonstrate common Mastra use cases and patterns
- [Introduction | Mastra Docs](https://mastra.ai/en/docs): Mastra is a TypeScript agent framework. It helps you build AI applications and features quickly. It gives you the set of primitives you need: workflows, agents, RAG, integrations, syncs and evals.
- [Understanding the Mastra Cloud Dashboard](https://mastra.ai/en/docs/mastra-cloud/dashboard): Details of each feature available in Mastra Cloud
- [Observability in Mastra Cloud](https://mastra.ai/en/docs/mastra-cloud/observability): Monitoring and debugging tools for Mastra Cloud deployments
- [Mastra Cloud](https://mastra.ai/en/docs/mastra-cloud/overview): Deployment and monitoring service for Mastra applications
- [Setting Up a Project](https://mastra.ai/en/docs/mastra-cloud/setting-up): Configuration steps for Mastra Cloud projects
- [memory-processors](https://mastra.ai/en/docs/memory/memory-processors)
- [overview](https://mastra.ai/en/docs/memory/overview)
- [semantic-recall](https://mastra.ai/en/docs/memory/semantic-recall)
- [working-memory](https://mastra.ai/en/docs/memory/working-memory)
- [complex-task-execution](https://mastra.ai/en/docs/networks-vnext/complex-task-execution)
- [Handling Complex LLM Operations | Networks | Mastra](https://mastra.ai/en/docs/networks-vnext/overview): Networks in Mastra help you execute individual or multiple Mastra primitives in a non-deterministic way using a single API.
- [single-task-execution](https://mastra.ai/en/docs/networks-vnext/single-task-execution)
- [Logging | Mastra Observability Documentation](https://mastra.ai/en/docs/observability/logging): Learn how to use logging in Mastra to monitor execution, capture application behavior, and improve the accuracy of AI applications.
- [Next.js Tracing | Mastra Observability Documentation](https://mastra.ai/en/docs/observability/nextjs-tracing): Set up OpenTelemetry tracing for Next.js applications
- [Tracing | Mastra Observability Documentation](https://mastra.ai/en/docs/observability/tracing): Set up OpenTelemetry tracing for Mastra applications
- [Chunking and Embedding Documents | RAG | Mastra Docs](https://mastra.ai/en/docs/rag/chunking-and-embedding): Guide on chunking and embedding documents in Mastra for efficient processing and retrieval.
- [RAG (Retrieval-Augmented Generation) in Mastra | Mastra Docs](https://mastra.ai/en/docs/rag/overview): Overview of Retrieval-Augmented Generation (RAG) in Mastra, detailing its capabilities for enhancing LLM outputs with relevant context.
- [Retrieval, Semantic Search, Reranking | RAG | Mastra Docs](https://mastra.ai/en/docs/rag/retrieval): Guide on retrieval processes in Mastras RAG systems, including semantic search, filtering, and re-ranking.
- [Storing Embeddings in A Vector Database | Mastra Docs](https://mastra.ai/en/docs/rag/vector-databases): Guide on vector storage options in Mastra, including embedded and dedicated vector databases for similarity search.
- [custom-scorers](https://mastra.ai/en/docs/scorers/custom-scorers)
- [Built-in Scorers](https://mastra.ai/en/docs/scorers/off-the-shelf-scorers): Overview of Mastras ready-to-use scorers for evaluating AI outputs across quality, safety, and performance dimensions.
- [Overview](https://mastra.ai/en/docs/scorers/overview): Overview of scorers in Mastra, detailing their capabilities for evaluating AI outputs and measuring performance.
- [Custom API Routes](https://mastra.ai/en/docs/server-db/custom-api-routes): Expose additional HTTP endpoints from your Mastra server.
- [Inspecting agents and workflows with mastra dev | Mastra Local Dev Docs](https://mastra.ai/en/docs/server-db/local-dev-playground): Documentation for the Mastra local development environment for Mastra applications.
- [MastraClient](https://mastra.ai/en/docs/server-db/mastra-client): Learn how to set up and use the Mastra Client SDK
- [Middleware](https://mastra.ai/en/docs/server-db/middleware): Apply custom middleware functions to intercept requests.
- [Create A Mastra Production Server](https://mastra.ai/en/docs/server-db/production-server): Learn how to configure and deploy a production-ready Mastra server with custom settings for APIs, CORS, and more
- [Reference: Snapshots | Workflow State Persistence | Mastra Docs](https://mastra.ai/en/docs/server-db/snapshots): Technical reference on snapshots in Mastra - the serialized workflow state that enables suspend and resume functionality
- [Storage in Mastra | Mastra Docs](https://mastra.ai/en/docs/server-db/storage): Overview of Mastras storage system and data persistence capabilities.
- [Streaming Events | Streaming | Mastra](https://mastra.ai/en/docs/streaming/events): Learn about the different types of streaming events in Mastra, including text deltas, tool calls, step events, and how to handle them in your applications.
- [Streaming Overview | Streaming | Mastra](https://mastra.ai/en/docs/streaming/overview): Streaming in Mastra enables real-time, incremental responses from both agents and workflows, providing immediate feedback as AI-generated content is produced.
- [Tool Streaming | Streaming | Mastra](https://mastra.ai/en/docs/streaming/tool-streaming): Learn how to use tool streaming in Mastra, including handling tool calls, tool results, and tool execution events during streaming.
- [Workflow Streaming | Streaming | Mastra](https://mastra.ai/en/docs/streaming/workflow-streaming): Learn how to use workflow streaming in Mastra, including handling workflow execution events, step streaming, and workflow integration with agents and tools.
- [Advanced Tool Usage | Tools & MCP | Mastra Docs](https://mastra.ai/en/docs/tools-mcp/advanced-usage): This page covers advanced features for Mastra tools, including abort signals and compatibility with the Vercel AI SDK tool format.
- [Dynamic Tool Context | Tools & MCP | Mastra Docs](https://mastra.ai/en/docs/tools-mcp/dynamic-context): Learn how to use Mastras RuntimeContext to provide dynamic, request-specific configuration to tools.
- [MCP Overview | Tools & MCP | Mastra Docs](https://mastra.ai/en/docs/tools-mcp/mcp-overview): Learn about the Model Context Protocol (MCP), how to use third-party tools via MCPClient, connect to registries, and share your own tools using MCPServer.
- [Tools Overview | Tools & MCP | Mastra Docs](https://mastra.ai/en/docs/tools-mcp/overview): Understand what tools are in Mastra, how to add them to agents, and best practices for designing effective tools.
- [Voice in Mastra | Mastra Docs](https://mastra.ai/en/docs/voice/overview): Overview of voice capabilities in Mastra, including text-to-speech, speech-to-text, and real-time speech-to-speech interactions.
- [Speech-to-Speech Capabilities in Mastra | Mastra Docs](https://mastra.ai/en/docs/voice/speech-to-speech): Overview of speech-to-speech capabilities in Mastra, including real-time interactions and event-driven architecture.
- [Speech-to-Text (STT) in Mastra | Mastra Docs](https://mastra.ai/en/docs/voice/speech-to-text): Overview of Speech-to-Text capabilities in Mastra, including configuration, usage, and integration with voice providers.
- [Text-to-Speech (TTS) in Mastra | Mastra Docs](https://mastra.ai/en/docs/voice/text-to-speech): Overview of Text-to-Speech capabilities in Mastra, including configuration, usage, and integration with voice providers.
- [Branching, Merging, Conditions | Workflows | Mastra Docs](https://mastra.ai/en/docs/workflows/control-flow): Control flow in Mastra workflows allows you to manage branching, merging, and conditions to construct workflows that meet your logic requirements.
- [Error Handling in Workflows | Workflows | Mastra Docs](https://mastra.ai/en/docs/workflows/error-handling): Learn how to handle errors in Mastra workflows using step retries, conditional branching, and monitoring.
- [Inngest Workflows | Workflows | Mastra Docs](https://mastra.ai/en/docs/workflows/inngest-workflow): Inngest workflow allows you to run Mastra workflows with Inngest
- [Input Data Mapping with Workflow | Mastra Docs](https://mastra.ai/en/docs/workflows/input-data-mapping): Learn how to use workflow input mapping to create more dynamic data flows in your Mastra workflows.
- [Handling Complex LLM Operations | Workflows | Mastra](https://mastra.ai/en/docs/workflows/overview): Workflows in Mastra help you orchestrate complex sequences of operations with features like branching, parallel execution, resource suspension, and more.
- [Pausing Execution | Mastra Docs](https://mastra.ai/en/docs/workflows/pausing-execution): Pausing execution in Mastra workflows allows you to pause execution while waiting for external input or resources via .sleep(), .sleepUntil() and .waitForEvent().
- [Suspend & Resume Workflows | Human-in-the-Loop | Mastra Docs](https://mastra.ai/en/docs/workflows/suspend-and-resume): Suspend and resume in Mastra workflows allows you to pause execution while waiting for external input or resources.
- [Using Workflows with Agents and Tools | Workflows | Mastra Docs](https://mastra.ai/en/docs/workflows/using-with-agents-and-tools): Steps in Mastra workflows provide a structured way to manage operations by defining inputs, outputs, and execution logic.
- [Branching, Merging, Conditions | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/docs/workflows-legacy/control-flow): Control flow in Mastra legacy workflows allows you to manage branching, merging, and conditions to construct legacy workflows that meet your logic requirements.
- [Dynamic Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/docs/workflows-legacy/dynamic-workflows): Learn how to create dynamic workflows within legacy workflow steps, allowing for flexible workflow creation based on runtime conditions.
- [Error Handling in Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/docs/workflows-legacy/error-handling): Learn how to handle errors in Mastra legacy workflows using step retries, conditional branching, and monitoring.
- [nested-workflows](https://mastra.ai/en/docs/workflows-legacy/nested-workflows)
- [Handling Complex LLM Operations | Workflows (Legacy) | Mastra](https://mastra.ai/en/docs/workflows-legacy/overview): Workflows in Mastra help you orchestrate complex sequences of operations with features like branching, parallel execution, resource suspension, and more.
- [Runtime variables - dependency injection | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/docs/workflows-legacy/runtime-variables): Learn how to use Mastras dependency injection system to provide runtime configuration to workflows and steps.
- [Creating Steps and Adding to Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/docs/workflows-legacy/steps): Steps in Mastra workflows provide a structured way to manage operations by defining inputs, outputs, and execution logic.
- [Suspend & Resume Workflows (Legacy) | Human-in-the-Loop | Mastra Docs](https://mastra.ai/en/docs/workflows-legacy/suspend-and-resume): Suspend and resume in Mastra workflows allows you to pause execution while waiting for external input or resources.
- [Data Mapping with Workflow (Legacy) Variables | Mastra Docs](https://mastra.ai/en/docs/workflows-legacy/variables): Learn how to use workflow variables to map data between steps and create dynamic data flows in your Mastra workflows.

## EN - examples
- [Example: Adding Voice Capabilities | Agents | Mastra](https://mastra.ai/en/examples/agents/adding-voice-capabilities): Example of adding voice capabilities to Mastra agents, enabling them to speak and listen using different voice providers.
- [Example: AI SDK v5 Integration | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/ai-sdk-v5-integration): Example of integrating Mastra agents with AI SDK v5 for streaming chat interfaces with memory and tool integration.
- [Calling Agents | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/calling-agents): Example for how to call agents.
- [Example: Deploying an MCPServer | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/deploying-mcp-server): Example of setting up, building, and deploying a Mastra MCPServer using the stdio transport and publishing it to NPM.
- [Dynamic Context Example | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/dynamic-agents): Learn how to create and configure dynamic agents using runtime context in Mastra.
- [Example: Image Analysis Agent | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/image-analysis): Example of using a Mastra AI Agent to analyze images from Unsplash to identify objects, determine species, and describe locations.
- [Example: Supervisor agent | Agents | Mastra](https://mastra.ai/en/examples/agents/supervisor-agent): Example of creating a supervisor agent using Mastra, where agents interact through tool functions.
- [Example: Agents with a System Prompt | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/system-prompt): Example of creating an AI agent in Mastra with a system prompt to define its personality and capabilities.
- [Example: Adding Tools to Agents | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/using-a-tool): Example of creating an AI agent in Mastra that uses a dedicated tool to provide weather information.
- [Example: Adding Workflows to Agents | Agents | Mastra Docs](https://mastra.ai/en/examples/agents/using-a-workflow): Example of creating an AI agent in Mastra that uses a dedicated workflow to provide soccer fixture information.
- [Auth Middleware](https://mastra.ai/en/examples/deployment/auth-middleware)
- [CORS Middleware](https://mastra.ai/en/examples/deployment/cors-middleware)
- [Custom API Route](https://mastra.ai/en/examples/deployment/custom-api-route)
- [Deploying a Mastra Server](https://mastra.ai/en/examples/deployment/deploying-mastra-server)
- [Deployment examples](https://mastra.ai/en/examples/deployment)
- [Logging Middleware](https://mastra.ai/en/examples/deployment/logging-middleware)
- [Example: Answer Relevancy | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/answer-relevancy): Example of using the Answer Relevancy metric to evaluate response relevancy to queries.
- [Example: Bias | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/bias): Example of using the Bias metric to evaluate responses for various forms of bias.
- [Example: Completeness | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/completeness): Example of using the Completeness metric to evaluate how thoroughly responses cover input elements.
- [Example: Content Similarity | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/content-similarity): Example of using the Content Similarity metric to evaluate text similarity between content.
- [Example: Context Position | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/context-position): Example of using the Context Position metric to evaluate sequential ordering in responses.
- [Example: Context Precision | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/context-precision): Example of using the Context Precision metric to evaluate how precisely context information is used.
- [Example: Context Relevancy | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/context-relevancy): Example of using the Context Relevancy metric to evaluate how relevant context information is to a query.
- [Example: Contextual Recall | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/contextual-recall): Example of using the Contextual Recall metric to evaluate how well responses incorporate context information.
- [Example: Real World Countries | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/custom-llm-judge-eval): Example of creating a custom LLM-based evaluation metric.
- [Example: Word Inclusion | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/custom-native-javascript-eval): Example of creating a custom native JavaScript evaluation metric.
- [Example: Faithfulness | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/faithfulness): Example of using the Faithfulness metric to evaluate how factually accurate responses are compared to context.
- [Example: Hallucination | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/hallucination): Example of using the Hallucination metric to evaluate factual contradictions in responses.
- [Example: Keyword Coverage | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/keyword-coverage): Example of using the Keyword Coverage metric to evaluate how well responses cover important keywords from input text.
- [Example: Prompt Alignment | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/prompt-alignment): Example of using the Prompt Alignment metric to evaluate instruction adherence in responses.
- [Example: Summarization | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/summarization): Example of using the Summarization metric to evaluate how well LLM-generated summaries capture content while maintaining factual accuracy.
- [Example: Textual Difference | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/textual-difference): Example of using the Textual Difference metric to evaluate similarity between text strings by analyzing sequence differences and changes.
- [Example: Tone Consistency | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/tone-consistency): Example of using the Tone Consistency metric to evaluate emotional tone patterns and sentiment consistency in text.
- [Example: Toxicity | Evals | Mastra Docs](https://mastra.ai/en/examples/evals/toxicity): Example of using the Toxicity metric to evaluate responses for harmful content and toxic language.
- [Examples List: Workflows, Agents, RAG | Mastra Docs](https://mastra.ai/en/examples): Explore practical examples of AI development with Mastra, including text generation, RAG implementations, structured outputs, and multi-modal interactions. Learn how to build AI applications using OpenAI, Anthropic, and Google Gemini.
- [Memory Processors](https://mastra.ai/en/examples/memory/memory-processors): Example of using memory processors to filter and transform recalled messages
- [memory-with-libsql](https://mastra.ai/en/examples/memory/memory-with-libsql)
- [memory-with-mem0](https://mastra.ai/en/examples/memory/memory-with-mem0)
- [memory-with-pg](https://mastra.ai/en/examples/memory/memory-with-pg)
- [memory-with-upstash](https://mastra.ai/en/examples/memory/memory-with-upstash)
- [Streaming Working Memory (advanced)](https://mastra.ai/en/examples/memory/streaming-working-memory-advanced): Example of using working memory to maintain a todo list across conversations
- [Streaming Structured Working Memory](https://mastra.ai/en/examples/memory/streaming-working-memory-structured): Example of using structured working memory (schema) to maintain a todo list across conversations
- [Streaming Working Memory](https://mastra.ai/en/examples/memory/streaming-working-memory): Example of using working memory with an agent
- [AI SDK useChat Hook](https://mastra.ai/en/examples/memory/use-chat): Example showing how to integrate Mastra memory with the Vercel AI SDK useChat hook.
- [Example: Adjusting Chunk Delimiters | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/adjust-chunk-delimiters): Adjust chunk delimiters in Mastra to better match your content structure.
- [Example: Adjusting The Chunk Size | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/adjust-chunk-size): Adjust chunk size in Mastra to better match your content and memory requirements.
- [Example: Semantically Chunking HTML | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/chunk-html): Chunk HTML content in Mastra to semantically chunk the document.
- [Example: Semantically Chunking JSON | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/chunk-json): Chunk JSON data in Mastra to semantically chunk the document.
- [Example: Semantically Chunking Markdown | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/chunk-markdown): Example of using Mastra to chunk markdown documents for search or retrieval purposes.
- [Example: Semantically Chunking Text | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/chunking/chunk-text): Example of using Mastra to split large text documents into smaller chunks for processing.
- [Example: Embedding Chunk Arrays | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/embedding/embed-chunk-array): Example of using Mastra to generate embeddings for an array of text chunks for similarity search.
- [Example: Embedding Text Chunks | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/embedding/embed-text-chunk): Example of using Mastra to generate an embedding for a single text chunk for similarity search.
- [Example: Embedding Text with Cohere | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/embedding/embed-text-with-cohere): Example of using Mastra to generate embeddings using Coheres embedding model.
- [Example: Metadata Extraction | Retrieval | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/embedding/metadata-extraction): Example of extracting and utilizing metadata from documents in Mastra for enhanced document processing and retrieval.
- [Example: Hybrid Vector Search | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/query/hybrid-vector-search): Example of using metadata filters with PGVector to enhance vector search results in Mastra.
- [Example: Retrieving Top-K Results | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/query/retrieve-results): Example of using Mastra to query a vector database and retrieve semantically similar chunks.
- [Example: Re-ranking Results with Tools | Retrieval | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/rerank/rerank-rag): Example of implementing a RAG system with re-ranking in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Re-ranking Results | Retrieval | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/rerank/rerank): Example of implementing semantic re-ranking in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Reranking with Cohere | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/rerank/reranking-with-cohere): Example of using Mastra to improve document retrieval relevance with Coheres reranking service.
- [Example: Reranking with ZeroEntropy | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/rerank/reranking-with-zeroentropy): Example of using Mastra to improve document retrieval relevance with ZeroEntropys reranking service.
- [Example: Upsert Embeddings | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/upsert/upsert-embeddings): Examples of using Mastra to store embeddings in various vector databases for similarity search.
- [Example: Using the Vector Query Tool | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/basic-rag): Example of implementing a basic RAG system in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Optimizing Information Density | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/cleanup-rag): Example of implementing a RAG system in Mastra to optimize information density and deduplicate data using LLM-based processing.
- [Example: Chain of Thought Prompting | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/cot-rag): Example of implementing a RAG system in Mastra with chain-of-thought reasoning using OpenAI and PGVector.
- [Example: Structured Reasoning with Workflows | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/cot-workflow-rag): Example of implementing structured reasoning in a RAG system using Mastras workflow capabilities.
- [Database-Specific Configurations | RAG | Mastra Examples](https://mastra.ai/en/examples/rag/usage/database-specific-config): Learn how to use database-specific configurations to optimize vector search performance and leverage unique features of different vector stores.
- [Example: Agent-Driven Metadata Filtering | Retrieval | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/filter-rag): Example of using a Mastra agent in a RAG system to construct and apply metadata filters for document retrieval.
- [Example: A Complete Graph RAG System | RAG | Mastra Docs](https://mastra.ai/en/examples/rag/usage/graph-rag): Example of implementing a Graph RAG system in Mastra using OpenAI embeddings and PGVector for vector storage.
- [Example: Answer Relevancy | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/answer-relevancy): Example of using the Answer Relevancy scorer to evaluate response relevancy to queries.
- [Example: Bias | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/bias): Example of using the Bias scorer to evaluate responses for various forms of bias.
- [Example: Completeness | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/completeness): Example of using the Completeness scorer to evaluate how thoroughly responses address all aspects of a query.
- [Example: Content Similarity | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/content-similarity): Example of using the Content Similarity scorer to evaluate text similarity between content.
- [Example: Context Precision Scorer | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/context-precision): Example of using the Context Precision scorer to evaluate the relevance and positioning of retrieved context for RAG systems using Mean Average Precision.
- [Example: Context Relevance Scorer | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/context-relevance): Example of using the Context Relevance scorer to evaluate how relevant and useful provided context is for generating agent responses.
- [Example: Custom Judge | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/custom-scorer): Example of creating a custom based scorer using createScorer with prompt objects.
- [Example: Faithfulness | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/faithfulness): Example of using the Faithfulness scorer to evaluate how factually accurate responses are compared to context.
- [Example: Hallucination | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/hallucination): Example of using the Hallucination scorer to evaluate factual contradictions in responses.
- [Example: Keyword Coverage | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/keyword-coverage): Example of using the Keyword Coverage scorer to evaluate how well responses cover important keywords from input text.
- [Example: Textual Difference | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/textual-difference): Example of using the Textual Difference scorer to evaluate similarity between text strings by analyzing sequence differences and changes.
- [Example: Tone Consistency | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/tone-consistency): Example of using the Tone Consistency scorer to evaluate emotional tone patterns and sentiment consistency in text.
- [Example: Tool Call Accuracy | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/tool-call-accuracy): Examples of using the Tool Call Accuracy scorers to evaluate whether LLMs select the correct tools for specific tasks.
- [Example: Toxicity | Scorers | Mastra Docs](https://mastra.ai/en/examples/scorers/toxicity): Example of using the Toxicity scorer to evaluate responses for harmful content and toxic language.
- [Calling Tools | Tools | Mastra Docs](https://mastra.ai/en/examples/tools/calling-tools): Example for how to tools agents.
- [Dynamic Tools Example | Tools | Mastra Docs](https://mastra.ai/en/examples/tools/dynamic-tools): Learn how to create and configure dynamic tools using runtime context in Mastra.
- [Example: Workflows as Tools | Agents | Mastra Docs](https://mastra.ai/en/examples/tools/workflow-as-tools): Example of using workflows as tools, demonstrating how to create reusable workflow components that can be called like tools.
- [Speech to Speech](https://mastra.ai/en/examples/voice/speech-to-speech): Example of using Mastra to create a speech to speech application.
- [Example: Speech to Text | Voice | Mastra Docs](https://mastra.ai/en/examples/voice/speech-to-text): Example of using Mastra to create a speech to text application.
- [Example: Text to Speech | Voice | Mastra Docs](https://mastra.ai/en/examples/voice/text-to-speech): Example of using Mastra to create a text to speech application.
- [Turn Taking](https://mastra.ai/en/examples/voice/turn-taking): Example of using Mastra to create a multi-agent debate with turn-taking conversation flow.
- [Example: Using an Agent as a Step | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/agent-as-step): Example of using Mastra to integrate an agent as a step in a workflow.
- [Example: Array as Input (.foreach()) | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/array-as-input): Example of using Mastra to process an array using .foreach() in a workflow.
- [Example: Calling an Agent from a Workflow | Mastra Docs](https://mastra.ai/en/examples/workflows/calling-agent): Example of using Mastra to call an AI agent from within a workflow step.
- [Example: Conditional Branching | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/conditional-branching): Example of using Mastra to create conditional branches in workflows using the `branch` statement .
- [Example: Multi-Turn Human in the Loop | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/human-in-the-loop-multi-turn): Example of using Mastra to create workflows with multi-turn human/agent interaction points using suspend/resume and dountil methods.
- [Example: Human in the Loop | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/human-in-the-loop): Example of using Mastra to create workflows with human intervention points.
- [Inngest Workflow | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/inngest-workflow): Example of building an inngest workflow with Mastra
- [Example: Parallel Execution | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/parallel-steps): Example of using Mastra to execute multiple independent tasks in parallel within a workflow.
- [Running Workflows | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/running-workflows): Example for how to run workflows.
- [Example: Sequential Execution | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/sequential-steps): Example of using Mastra to execute multiple independent tasks in sequence within a workflow.
- [Example: Using a Tool as a Step | Workflows | Mastra Docs](https://mastra.ai/en/examples/workflows/tool-as-step): Example of using Mastra to integrate a tool as a step in a workflow.
- [Example: Branching Paths | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/branching-paths): Example of using Mastra to create legacy workflows with branching paths based on intermediate results.
- [Example: Calling an Agent from a Workflow (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/calling-agent): Example of using Mastra to call an AI agent from within a legacy workflow step.
- [Example: Conditional Branching (experimental) | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/conditional-branching): Example of using Mastra to create conditional branches in legacy workflows using if/else statements.
- [Example: Creating a Workflow | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/creating-a-workflow): Example of using Mastra to define and execute a simple workflow with a single step.
- [Example: Cyclical Dependencies | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/cyclical-dependencies): Example of using Mastra to create legacy workflows with cyclical dependencies and conditional loops.
- [Example: Human in the Loop | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/human-in-the-loop): Example of using Mastra to create legacy workflows with human intervention points.
- [Example: Parallel Execution | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/parallel-steps): Example of using Mastra to execute multiple independent tasks in parallel within a workflow.
- [Example: Sequential Steps | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/sequential-steps): Example of using Mastra to chain legacy workflow steps in a specific sequence, passing data between them.
- [Example: Suspend and Resume | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/suspend-and-resume): Example of using Mastra to suspend and resume legacy workflow steps during execution.
- [Example: Using a Tool as a Step | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/examples/workflows_legacy/using-a-tool-as-a-step): Example of using Mastra to integrate a custom tool as a step in a legacy workflow.
- [Data Mapping with Workflow Variables (Legacy) | Mastra Examples](https://mastra.ai/en/examples/workflows_legacy/workflow-variables): Learn how to use workflow variables to map data between steps in Mastra workflows.

## EN - guides
- [Building an AI Recruiter | Mastra Workflows | Guides](https://mastra.ai/en/guides/guide/ai-recruiter): Guide on building a recruiter workflow in Mastra to gather and process candidate information using LLMs.
- [Building an AI Chef Assistant | Mastra Agent Guides](https://mastra.ai/en/guides/guide/chef-michel): Guide on creating a Chef Assistant agent in Mastra to help users cook meals with available ingredients.
- [MCP Server: Building a Notes MCP Server | Mastra Guide](https://mastra.ai/en/guides/guide/notes-mcp-server): A step-by-step guide to creating a fully-featured MCP (Model Context Protocol) server for managing notes using the Mastra framework.
- [Building a Research Paper Assistant | Mastra RAG Guides](https://mastra.ai/en/guides/guide/research-assistant): Guide on creating an AI research assistant that can analyze and answer questions about academic papers using RAG.
- [Building an AI Stock Agent | Mastra Agents | Guides](https://mastra.ai/en/guides/guide/stock-agent): Guide on creating a simple stock agent in Mastra to fetch the last days closing stock price for a given symbol.
- [Overview](https://mastra.ai/en/guides): Guides on building with Mastra

## EN - reference
- [Reference: Agent Class | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/agent): Documentation for the `Agent` class in Mastra, which provides the foundation for creating AI agents with various capabilities.
- [Reference: Agent.generate() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/generate): Documentation for the `Agent.generate()` method in Mastra agents, which produces text or structured responses.
- [Reference: Agent.getAgent() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getAgent): Documentation for the `Agent.getAgent()` method in Mastra, which retrieves an agent by name.
- [Reference: Agent.getDefaultGenerateOptions() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getDefaultGenerateOptions): Documentation for the `Agent.getDefaultGenerateOptions()` method in Mastra agents, which retrieves the default options used for generate calls.
- [Reference: Agent.getDefaultStreamOptions() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getDefaultStreamOptions): Documentation for the `Agent.getDefaultStreamOptions()` method in Mastra agents, which retrieves the default options used for stream calls.
- [Reference: Agent.getDefaultVNextStreamOptions() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getDefaultVNextStreamOptions): Documentation for the `Agent.getDefaultVNextStreamOptions()` method in Mastra agents, which retrieves the default options used for streamVNext calls.
- [Reference: Agent.getDescription() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getDescription): Documentation for the `Agent.getDescription()` method in Mastra agents, which retrieves the agents description.
- [Reference: Agent.getInstructions() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getInstructions): Documentation for the `Agent.getInstructions()` method in Mastra agents, which retrieves the instructions that guide the agents behavior.
- [Reference: Agent.getLLM() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getLLM): Documentation for the `Agent.getLLM()` method in Mastra agents, which retrieves the language model instance.
- [Reference: Agent.getMemory() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getMemory): Documentation for the `Agent.getMemory()` method in Mastra agents, which retrieves the memory system associated with the agent.
- [Reference: Agent.getModel() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getModel): Documentation for the `Agent.getModel()` method in Mastra agents, which retrieves the language model that powers the agent.
- [Reference: Agent.getScorers() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getScorers): Documentation for the `Agent.getScorers()` method in Mastra agents, which retrieves the scoring configuration.
- [Reference: Agent.getTools() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getTools): Documentation for the `Agent.getTools()` method in Mastra agents, which retrieves the tools that the agent can use.
- [Reference: Agent.getVoice() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getVoice): Documentation for the `Agent.getVoice()` method in Mastra agents, which retrieves the voice provider for speech capabilities.
- [Reference: Agent.getWorkflows() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/getWorkflows): Documentation for the `Agent.getWorkflows()` method in Mastra agents, which retrieves the workflows that the agent can execute.
- [Reference: Agent.stream() | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/stream): Documentation for the `Agent.stream()` method in Mastra agents, which enables real-time streaming of responses.
- [Reference: Agent.streamVNext() (Experimental) | Agents | Mastra Docs](https://mastra.ai/en/reference/agents/streamVNext): Documentation for the `Agent.streamVNext()` method in Mastra agents, which enables real-time streaming of responses with enhanced capabilities.
- [MastraJwtAuth](https://mastra.ai/en/reference/auth/jwt): API reference for the MastraJwtAuth class, which authenticates Mastra applications using JSON Web Tokens.
- [mastra build | Production Bundle | Mastra CLI](https://mastra.ai/en/reference/cli/build): Build your Mastra project for production deployment
- [create-mastra | Create Project | Mastra CLI](https://mastra.ai/en/reference/cli/create-mastra): Documentation for the create-mastra command, which creates a new Mastra project with interactive setup options.
- [mastra dev | Development Server | Mastra CLI](https://mastra.ai/en/reference/cli/dev): Documentation for the mastra dev command, which starts a development server for agents, tools, and workflows.
- [mastra init | Initialize Project | Mastra CLI](https://mastra.ai/en/reference/cli/init): Documentation for the mastra init command, which creates a new Mastra project with interactive setup options.
- [mastra lint | Validate Project | Mastra CLI](https://mastra.ai/en/reference/cli/lint): Lint your Mastra project
- [@mastra/mcp-docs-server](https://mastra.ai/en/reference/cli/mcp-docs-server): Serve Mastra docs, examples and blog posts over MCP
- [mastra scorers | Evaluation Management | Mastra CLI](https://mastra.ai/en/reference/cli/scorers): Manage scorers for evaluating AI outputs with the Mastra CLI
- [mastra start](https://mastra.ai/en/reference/cli/start): Start your built Mastra application
- [Mastra Client Agents API](https://mastra.ai/en/reference/client-js/agents): Learn how to interact with Mastra AI agents, including generating responses, streaming interactions, and managing agent tools using the client-js SDK.
- [Mastra Client Error Handling](https://mastra.ai/en/reference/client-js/error-handling): Learn about the built-in retry mechanism and error handling capabilities in the Mastra client-js SDK.
- [Mastra Client Logs API](https://mastra.ai/en/reference/client-js/logs): Learn how to access and query system logs and debugging information in Mastra using the client-js SDK.
- [MastraClient](https://mastra.ai/en/reference/client-js/mastra-client): Learn how to interact with Mastra using the client-js SDK.
- [Mastra Client Memory API](https://mastra.ai/en/reference/client-js/memory): Learn how to manage conversation threads and message history in Mastra using the client-js SDK.
- [Mastra Client Telemetry API](https://mastra.ai/en/reference/client-js/telemetry): Learn how to retrieve and analyze traces from your Mastra application for monitoring and debugging using the client-js SDK.
- [Mastra Client Tools API](https://mastra.ai/en/reference/client-js/tools): Learn how to interact with and execute tools available in the Mastra platform using the client-js SDK.
- [Mastra Client Vectors API](https://mastra.ai/en/reference/client-js/vectors): Learn how to work with vector embeddings for semantic search and similarity matching in Mastra using the client-js SDK.
- [Mastra Client Workflows (Legacy) API](https://mastra.ai/en/reference/client-js/workflows-legacy): Learn how to interact with and execute automated legacy workflows in Mastra using the client-js SDK.
- [Mastra Client Workflows API](https://mastra.ai/en/reference/client-js/workflows): Learn how to interact with and execute automated workflows in Mastra using the client-js SDK.
- [Mastra Core](https://mastra.ai/en/reference/core/mastra-class): Documentation for the Mastra Class, the core entry point for managing agents, workflows, MCP servers, and server endpoints.
- [Cloudflare Deployer](https://mastra.ai/en/reference/deployer/cloudflare): Documentation for the CloudflareDeployer class, which deploys Mastra applications to Cloudflare Workers.
- [Mastra Deployer](https://mastra.ai/en/reference/deployer/deployer): Documentation for the Deployer abstract class, which handles packaging and deployment of Mastra applications.
- [Netlify Deployer](https://mastra.ai/en/reference/deployer/netlify): Documentation for the NetlifyDeployer class, which deploys Mastra applications to Netlify Functions.
- [Vercel Deployer](https://mastra.ai/en/reference/deployer/vercel): Documentation for the VercelDeployer class, which deploys Mastra applications to Vercel.
- [Reference: Answer Relevancy | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/answer-relevancy): Documentation for the Answer Relevancy Metric in Mastra, which evaluates how well LLM outputs address the input query.
- [Reference: Bias | Output Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/bias): Documentation for the Bias Metric in Mastra, which evaluates LLM outputs for various forms of bias, including gender, political, racial/ethnic, or geographical bias.
- [Reference: Completeness | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/completeness): Documentation for the Completeness Metric in Mastra, which evaluates how thoroughly LLM outputs cover key elements present in the input.
- [Reference: Content Similarity | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/content-similarity): Documentation for the Content Similarity Metric in Mastra, which measures textual similarity between strings and provides a matching score.
- [Reference: Context Position | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/context-position): Documentation for the Context Position Metric in Mastra, which evaluates the ordering of context nodes based on their relevance to the query and output.
- [Reference: Context Precision | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/context-precision): Documentation for the Context Precision Metric in Mastra, which evaluates the relevance and precision of retrieved context nodes for generating expected outputs.
- [Reference: Context Relevancy | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/context-relevancy): Documentation for the Context Relevancy Metric, which evaluates the relevance of retrieved context in RAG pipelines.
- [Reference: Contextual Recall | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/contextual-recall): Documentation for the Contextual Recall Metric, which evaluates the completeness of LLM responses in incorporating relevant context.
- [Reference: Faithfulness | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/faithfulness): Documentation for the Faithfulness Metric in Mastra, which evaluates the factual accuracy of LLM outputs compared to the provided context.
- [Reference: Hallucination | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/hallucination): Documentation for the Hallucination Metric in Mastra, which evaluates the factual correctness of LLM outputs by identifying contradictions with provided context.
- [Reference: Keyword Coverage | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/keyword-coverage): Documentation for the Keyword Coverage Metric in Mastra, which evaluates how well LLM outputs cover important keywords from the input.
- [Reference: Prompt Alignment | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/prompt-alignment): Documentation for the Prompt Alignment Metric in Mastra, which evaluates how well LLM outputs adhere to given prompt instructions.
- [Reference: Summarization | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/summarization): Documentation for the Summarization Metric in Mastra, which evaluates the quality of LLM-generated summaries for content and factual accuracy.
- [Reference: Textual Difference | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/textual-difference): Documentation for the Textual Difference Metric in Mastra, which measures textual differences between strings using sequence matching.
- [Reference: Tone Consistency | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/tone-consistency): Documentation for the Tone Consistency Metric in Mastra, which evaluates emotional tone and sentiment consistency in text.
- [Reference: Toxicity | Metrics | Evals | Mastra Docs](https://mastra.ai/en/reference/evals/toxicity): Documentation for the Toxicity Metric in Mastra, which evaluates LLM outputs for racist, biased, or toxic elements.
- [API Reference](https://mastra.ai/en/reference): Mastra API Reference
- [Reference: .after() | Building Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/after): Documentation for the `after()` method in workflows (legacy), enabling branching and merging paths.
- [.afterEvent() Method | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/afterEvent): Reference for the afterEvent method in Mastra workflows that creates event-based suspension points.
- [Reference: Workflow.commit() | Running Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/commit): Documentation for the `.commit()` method in workflows, which re-initializes the workflow machine with the current step configuration.
- [Reference: Workflow.createRun() | Running Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/createRun): Documentation for the `.createRun()` method in workflows (legacy), which initializes a new workflow run instance.
- [Reference: Workflow.else() | Conditional Branching | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/else): Documentation for the `.else()` method in Mastra workflows, which creates an alternative branch when an if condition is false.
- [Event-Driven Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/events): Learn how to create event-driven workflows using afterEvent and resumeWithEvent methods in Mastra.
- [Reference: Workflow.execute() | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/execute): Documentation for the `.execute()` method in Mastra workflows, which runs workflow steps and returns results.
- [Reference: Workflow.if() | Conditional Branching | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/if): Documentation for the `.if()` method in Mastra workflows, which creates conditional branches based on specified conditions.
- [Reference: run.resume() | Running Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/resume): Documentation for the `.resume()` method in workflows, which continues execution of a suspended workflow step.
- [.resumeWithEvent() Method | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/resumeWithEvent): Reference for the resumeWithEvent method that resumes suspended workflows using event data.
- [Reference: Snapshots | Workflow State Persistence (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/snapshots): Technical reference on snapshots in Mastra - the serialized workflow state that enables suspend and resume functionality
- [Reference: start() | Running Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/start): Documentation for the `start()` method in workflows, which begins execution of a workflow run.
- [Reference: Step | Building Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/step-class): Documentation for the Step class, which defines individual units of work within a workflow.
- [Reference: StepCondition | Building Workflows (Legacy) | Mastra](https://mastra.ai/en/reference/legacyWorkflows/step-condition): Documentation for the step condition class in workflows, which determines whether a step should execute based on the output of previous steps or trigger data.
- [Reference: Workflow.step() | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/step-function): Documentation for the `.step()` method in workflows, which adds a new step to the workflow.
- [Reference: StepOptions | Building Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/step-options): Documentation for the step options in workflows, which control variable mapping, execution conditions, and other runtime behavior.
- [Step Retries | Error Handling | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/step-retries): Automatically retry failed steps in Mastra workflows with configurable retry policies.
- [Reference: suspend() | Control Flow | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/suspend): Documentation for the suspend function in Mastra workflows, which pauses execution until resumed.
- [Reference: Workflow.then() | Building Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/then): Documentation for the `.then()` method in workflows, which creates sequential dependencies between steps.
- [Reference: Workflow.until() | Looping in Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/until): Documentation for the `.until()` method in Mastra workflows, which repeats a step until a specified condition becomes true.
- [Reference: run.watch() | Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/watch): Documentation for the `.watch()` method in workflows, which monitors the status of a workflow run.
- [Reference: Workflow.while() | Looping in Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/while): Documentation for the `.while()` method in Mastra workflows, which repeats a step as long as a specified condition remains true.
- [Reference: Workflow Class | Building Workflows (Legacy) | Mastra Docs](https://mastra.ai/en/reference/legacyWorkflows/workflow): Documentation for the Workflow class in Mastra, which enables you to create state machines for complex sequences of operations with conditional branching and data validation.
- [Memory](https://mastra.ai/en/reference/memory/Memory)
- [createThread](https://mastra.ai/en/reference/memory/createThread)
- [deleteMessages](https://mastra.ai/en/reference/memory/deleteMessages)
- [getThreadById](https://mastra.ai/en/reference/memory/getThreadById)
- [getThreadsByResourceId](https://mastra.ai/en/reference/memory/getThreadsByResourceId)
- [getThreadsByResourceIdPaginated](https://mastra.ai/en/reference/memory/getThreadsByResourceIdPaginated)
- [query](https://mastra.ai/en/reference/memory/query)
- [AgentNetwork (Experimental)](https://mastra.ai/en/reference/networks/agent-network): Reference documentation for the AgentNetwork class
- [Reference: PinoLogger | Mastra Observability Docs](https://mastra.ai/en/reference/observability/logger): Documentation for PinoLogger, which provides methods to record events at various severity levels.
- [Reference: OtelConfig | Mastra Observability Docs](https://mastra.ai/en/reference/observability/otel-config): Documentation for the OtelConfig object, which configures OpenTelemetry instrumentation, tracing, and exporting behavior.
- [Reference: Braintrust | Observability | Mastra Docs](https://mastra.ai/en/reference/observability/providers/braintrust): Documentation for integrating Braintrust with Mastra, an evaluation and monitoring platform for LLM applications.
- [Reference: Dash0 Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/dash0): Documentation for integrating Mastra with Dash0, an Open Telemetry native observability solution.
- [Reference: Provider List | Observability | Mastra Docs](https://mastra.ai/en/reference/observability/providers): Overview of observability providers supported by Mastra, including Dash0, SigNoz, Braintrust, Langfuse, and more.
- [Reference: Keywords AI Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/keywordsai): Documentation for integrating Keywords AI (an observability platform for LLM applications) with Mastra.
- [Reference: Laminar Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/laminar): Documentation for integrating Laminar with Mastra, a specialized observability platform for LLM applications.
- [Reference: Langfuse Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/langfuse): Documentation for integrating Langfuse with Mastra, an open-source observability platform for LLM applications.
- [Reference: LangSmith Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/langsmith): Documentation for integrating LangSmith with Mastra, a platform for debugging, testing, evaluating, and monitoring LLM applications.
- [Reference: LangWatch Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/langwatch): Documentation for integrating LangWatch with Mastra, a specialized observability platform for LLM applications.
- [Reference: New Relic Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/new-relic): Documentation for integrating New Relic with Mastra, a comprehensive observability platform supporting OpenTelemetry for full-stack monitoring.
- [Reference: SigNoz Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/signoz): Documentation for integrating SigNoz with Mastra, an open-source APM and observability platform providing full-stack monitoring through OpenTelemetry.
- [Reference: Traceloop Integration | Mastra Observability Docs](https://mastra.ai/en/reference/observability/providers/traceloop): Documentation for integrating Traceloop with Mastra, an OpenTelemetry-native observability platform for LLM applications.
- [Reference: Astra Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/astra): Documentation for the AstraVector class in Mastra, which provides vector search using DataStax Astra DB.
- [Reference: Chroma Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/chroma): Documentation for the ChromaVector class in Mastra, which provides vector search using ChromaDB.
- [Reference: .chunk() | Document Processing | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/chunk): Documentation for the chunk function in Mastra, which splits documents into smaller segments using various strategies.
- [Reference: Couchbase Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/couchbase): Documentation for the CouchbaseVector class in Mastra, which provides vector search using Couchbase Vector Search.
- [Reference: DatabaseConfig | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/database-config): API reference for database-specific configuration types used with vector query tools in Mastra RAG systems.
- [Reference: MDocument | Document Processing | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/document): Documentation for the MDocument class in Mastra, which handles document processing and chunking.
- [Reference: embed() | Document Embedding | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/embeddings): Documentation for embedding functionality in Mastra using the AI SDK.
- [Reference: ExtractParams | Document Processing | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/extract-params): Documentation for metadata extraction configuration in Mastra.
- [Reference: GraphRAG | Graph-based RAG | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/graph-rag): Documentation for the GraphRAG class in Mastra, which implements a graph-based approach to retrieval augmented generation.
- [Reference: Lance Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/lance): Documentation for the LanceVectorStore class in Mastra, which provides vector search using LanceDB, an embedded vector database based on the Lance columnar format.
- [Default Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/libsql): Documentation for the LibSQLVector class in Mastra, which provides vector search using LibSQL with vector extensions.
- [Reference: Metadata Filters | Metadata Filtering | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/metadata-filters): Documentation for metadata filtering capabilities in Mastra, which allow for precise querying of vector search results across different vector stores.
- [Reference: MongoDB Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/mongodb): Documentation for the MongoDBVector class in Mastra, which provides vector search using MongoDB Atlas and Atlas Vector Search.
- [Reference: OpenSearch Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/opensearch): Documentation for the OpenSearchVector class in Mastra, which provides vector search using OpenSearch.
- [Reference: PG Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/pg): Documentation for the PgVector class in Mastra, which provides vector search using PostgreSQL with pgvector extension.
- [Reference: Pinecone Vector Store | Vector DBs | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/pinecone): Documentation for the PineconeVector class in Mastra, which provides an interface to Pinecones vector database.
- [Reference: Qdrant Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/qdrant): Documentation for integrating Qdrant with Mastra, a vector similarity search engine for managing vectors and payloads.
- [Reference: Rerank | Document Retrieval | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/rerank): Documentation for the rerank function in Mastra, which provides advanced reranking capabilities for vector search results.
- [Reference: Rerank | Document Retrieval | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/rerankWithScorer): Documentation for the rerank function in Mastra, which provides advanced reranking capabilities for vector search results.
- [Reference: Turbopuffer Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/turbopuffer): Documentation for integrating Turbopuffer with Mastra, a high-performance vector database for efficient similarity search.
- [Reference: Upstash Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/upstash): Documentation for the UpstashVector class in Mastra, which provides vector search using Upstash Vector.
- [Reference: Cloudflare Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/en/reference/rag/vectorize): Documentation for the CloudflareVector class in Mastra, which provides vector search using Cloudflare Vectorize.
- [Reference: Answer Relevancy | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/answer-relevancy): Documentation for the Answer Relevancy Scorer in Mastra, which evaluates how well LLM outputs address the input query.
- [Reference: Bias | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/bias): Documentation for the Bias Scorer in Mastra, which evaluates LLM outputs for various forms of bias, including gender, political, racial/ethnic, or geographical bias.
- [Reference: Completeness | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/completeness): Documentation for the Completeness Scorer in Mastra, which evaluates how thoroughly LLM outputs cover key elements present in the input.
- [Reference: Content Similarity | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/content-similarity): Documentation for the Content Similarity Scorer in Mastra, which measures textual similarity between strings and provides a matching score.
- [Reference: Context Precision Scorer | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/context-precision): Documentation for the Context Precision Scorer in Mastra. Evaluates the relevance and precision of retrieved context for generating expected outputs using Mean Average Precision.
- [Reference: Context Relevance Scorer | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/context-relevance): Documentation for the Context Relevance Scorer in Mastra. Evaluates the relevance and utility of provided context for generating agent responses using weighted relevance scoring.
- [Reference: Create Custom Scorer | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/create-scorer): Documentation for creating custom scorers in Mastra, allowing users to define their own evaluation logic using either JavaScript functions or LLM-based prompts.
- [Reference: Faithfulness | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/faithfulness): Documentation for the Faithfulness Scorer in Mastra, which evaluates the factual accuracy of LLM outputs compared to the provided context.
- [Reference: Hallucination | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/hallucination): Documentation for the Hallucination Scorer in Mastra, which evaluates the factual correctness of LLM outputs by identifying contradictions with provided context.
- [Reference: Keyword Coverage | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/keyword-coverage): Documentation for the Keyword Coverage Scorer in Mastra, which evaluates how well LLM outputs cover important keywords from the input.
- [Reference: MastraScorer | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/mastra-scorer): Documentation for the MastraScorer base class in Mastra, which provides the foundation for all custom and built-in scorers.
- [Reference: Textual Difference | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/textual-difference): Documentation for the Textual Difference Scorer in Mastra, which measures textual differences between strings using sequence matching.
- [Reference: Tone Consistency | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/tone-consistency): Documentation for the Tone Consistency Scorer in Mastra, which evaluates emotional tone and sentiment consistency in text.
- [Reference: Tool Call Accuracy | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/tool-call-accuracy): Documentation for the Tool Call Accuracy Scorers in Mastra, which evaluate whether LLM outputs call the correct tools from available options.
- [Reference: Toxicity | Scorers | Mastra Docs](https://mastra.ai/en/reference/scorers/toxicity): Documentation for the Toxicity Scorer in Mastra, which evaluates LLM outputs for racist, biased, or toxic elements.
- [Cloudflare D1 Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/cloudflare-d1): Documentation for the Cloudflare D1 SQL storage implementation in Mastra.
- [Cloudflare Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/cloudflare): Documentation for the Cloudflare KV storage implementation in Mastra.
- [DynamoDB Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/dynamodb): Documentation for the DynamoDB storage implementation in Mastra, using a single-table design with ElectroDB.
- [LanceDB Storage](https://mastra.ai/en/reference/storage/lance): Documentation for the LanceDB storage implementation in Mastra.
- [LibSQL Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/libsql): Documentation for the LibSQL storage implementation in Mastra.
- [MSSQL Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/mssql): Documentation for the MSSQL storage implementation in Mastra.
- [PostgreSQL Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/postgresql): Documentation for the PostgreSQL storage implementation in Mastra.
- [Upstash Storage | Storage System | Mastra Core](https://mastra.ai/en/reference/storage/upstash): Documentation for the Upstash storage implementation in Mastra.
- [Templates Reference](https://mastra.ai/en/reference/templates): Complete guide to creating, using, and contributing Mastra templates
- [Reference: MastraMCPClient | Tool Discovery | Mastra Docs](https://mastra.ai/en/reference/tools/client): API Reference for MastraMCPClient - A client implementation for the Model Context Protocol.
- [Reference: createTool() | Tools | Mastra Docs](https://mastra.ai/en/reference/tools/create-tool): Documentation for the `createTool()` function in Mastra, used to define custom tools for agents.
- [Reference: createDocumentChunkerTool() | Tools | Mastra Docs](https://mastra.ai/en/reference/tools/document-chunker-tool): Documentation for the Document Chunker Tool in Mastra, which splits documents into smaller chunks for efficient processing and retrieval.
- [Reference: createGraphRAGTool() | RAG | Mastra Tools Docs](https://mastra.ai/en/reference/tools/graph-rag-tool): Documentation for the Graph RAG Tool in Mastra, which enhances RAG by building a graph of semantic relationships between documents.
- [Reference: MCPClient | Tool Management | Mastra Docs](https://mastra.ai/en/reference/tools/mcp-client): API Reference for MCPClient - A class for managing multiple Model Context Protocol servers and their tools.
- [Reference: MCPServer | Exposing Mastra Tools via MCP | Mastra Docs](https://mastra.ai/en/reference/tools/mcp-server): API Reference for MCPServer - A class for exposing Mastra tools and capabilities as a Model Context Protocol server.
- [Reference: createVectorQueryTool() | RAG | Mastra Tools Docs](https://mastra.ai/en/reference/tools/vector-query-tool): Documentation for the Vector Query Tool in Mastra, which facilitates semantic search over vector stores with filtering and reranking capabilities.
- [Reference: Azure Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/azure): Documentation for the AzureVoice class, providing text-to-speech and speech-to-text capabilities using Azure Cognitive Services.
- [Reference: Cloudflare Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/cloudflare): Documentation for the CloudflareVoice class, providing text-to-speech capabilities using Cloudflare Workers AI.
- [Reference: CompositeVoice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/composite-voice): Documentation for the CompositeVoice class, which enables combining multiple voice providers for flexible text-to-speech and speech-to-text operations.
- [Reference: Deepgram Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/deepgram): Documentation for the Deepgram voice implementation, providing text-to-speech and speech-to-text capabilities with multiple voice models and languages.
- [Reference: ElevenLabs Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/elevenlabs): Documentation for the ElevenLabs voice implementation, offering high-quality text-to-speech capabilities with multiple voice models and natural-sounding synthesis.
- [Reference: Google Gemini Live Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/google-gemini-live): Documentation for the GeminiLiveVoice class, providing real-time multimodal voice interactions using Googles Gemini Live API with support for both Gemini API and Vertex AI.
- [Reference: Google Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/google): Documentation for the Google Voice implementation, providing text-to-speech and speech-to-text capabilities.
- [Reference: MastraVoice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/mastra-voice): Documentation for the MastraVoice abstract base class, which defines the core interface for all voice services in Mastra, including speech-to-speech capabilities.
- [Reference: Murf Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/murf): Documentation for the Murf voice implementation, providing text-to-speech capabilities.
- [Reference: OpenAI Realtime Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/openai-realtime): Documentation for the OpenAIRealtimeVoice class, providing real-time text-to-speech and speech-to-text capabilities via WebSockets.
- [Reference: OpenAI Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/openai): Documentation for the OpenAIVoice class, providing text-to-speech and speech-to-text capabilities.
- [Reference: PlayAI Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/playai): Documentation for the PlayAI voice implementation, providing text-to-speech capabilities.
- [Reference: Sarvam Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/sarvam): Documentation for the Sarvam class, providing text-to-speech and speech-to-text capabilities.
- [Reference: Speechify Voice | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/speechify): Documentation for the Speechify voice implementation, providing text-to-speech capabilities.
- [Reference: voice.addInstructions() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.addInstructions): Documentation for the addInstructions() method available in voice providers, which adds instructions to guide the voice models behavior.
- [Reference: voice.addTools() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.addTools): Documentation for the addTools() method available in voice providers, which equips voice models with function calling capabilities.
- [Reference: voice.answer() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.answer): Documentation for the answer() method available in real-time voice providers, which triggers the voice provider to generate a response.
- [Reference: voice.close() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.close): Documentation for the close() method available in voice providers, which disconnects from real-time voice services.
- [Reference: voice.connect() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.connect): Documentation for the connect() method available in real-time voice providers, which establishes a connection for speech-to-speech communication.
- [Reference: Voice Events | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.events): Documentation for events emitted by voice providers, particularly for real-time voice interactions.
- [Reference: voice.getSpeakers() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.getSpeakers): Documentation for the getSpeakers() method available in voice providers, which retrieves available voice options.
- [Reference: voice.listen() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.listen): Documentation for the listen() method available in all Mastra voice providers, which converts speech to text.
- [Reference: voice.off() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.off): Documentation for the off() method available in voice providers, which removes event listeners for voice events.
- [Reference: voice.on() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.on): Documentation for the on() method available in voice providers, which registers event listeners for voice events.
- [Reference: voice.send() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.send): Documentation for the send() method available in real-time voice providers, which streams audio data for continuous processing.
- [Reference: voice.speak() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.speak): Documentation for the speak() method available in all Mastra voice providers, which converts text to speech.
- [Reference: voice.updateConfig() | Voice Providers | Mastra Docs](https://mastra.ai/en/reference/voice/voice.updateConfig): Documentation for the updateConfig() method available in voice providers, which updates the configuration of a voice provider at runtime.
- [Reference: Workflow.branch() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/branch): Documentation for the `Workflow.branch()` method in workflows, which creates conditional branches between steps.
- [Reference: Workflow.commit() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/commit): Documentation for the `Workflow.commit()` method in workflows, which finalizes the workflow and returns the final result.
- [Reference: Workflow.createRunAsync() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/create-run): Documentation for the `Workflow.createRunAsync()` method in workflows, which creates a new workflow run instance.
- [Reference: Workflow.dountil() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/dountil): Documentation for the `Workflow.dountil()` method in workflows, which creates a loop that executes a step until a condition is met.
- [Reference: Workflow.dowhile() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/dowhile): Documentation for the `Workflow.dowhile()` method in workflows, which creates a loop that executes a step while a condition is met.
- [Reference: Workflow.execute() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/execute): Documentation for the `Workflow.execute()` method in workflows, which executes a workflow directly and returns the output.
- [Reference: Workflow.foreach() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/foreach): Documentation for the `Workflow.foreach()` method in workflows, which creates a loop that executes a step for each item in an array.
- [Reference: Workflow.map() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/map): Documentation for the `Workflow.map()` method in workflows, which maps output data from a previous step to the input of a subsequent step.
- [Reference: Workflow.parallel() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/parallel): Documentation for the `Workflow.parallel()` method in workflows, which executes multiple steps in parallel.
- [Reference: Run.cancel() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/run-methods/cancel): Documentation for the `Run.cancel()` method in workflows, which cancels a workflow run.
- [Reference: Run.resume() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/run-methods/resume): Documentation for the `Run.resume()` method in workflows, which resumes a suspended workflow run with new data.
- [Reference: Run.start() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/run-methods/start): Documentation for the `Run.start()` method in workflows, which starts a workflow run with input data.
- [Reference: Run.stream() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/run-methods/stream): Documentation for the `Run.stream()` method in workflows, which allows you to monitor the execution of a workflow run as a stream.
- [Reference: Run.streamVNext() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/run-methods/streamVNext): Documentation for the `Run.streamVNext()` method in workflows, which enables real-time streaming of responses.
- [Reference: Run.watch() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/run-methods/watch): Documentation for the `Run.watch()` method in workflows, which allows you to monitor the execution of a workflow run.
- [Reference: Run Class | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/run): Documentation for the Run class in Mastra, which represents a workflow execution instance.
- [Reference: Workflow.sendEvent() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/sendEvent): Documentation for the `Workflow.sendEvent()` method in workflows, which resumes execution when an event is sent.
- [Reference: Workflow.sleep() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/sleep): Documentation for the `Workflow.sleep()` method in workflows, which pauses execution for a specified number of milliseconds.
- [Reference: Workflow.sleepUntil() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/sleepUntil): Documentation for the `Workflow.sleepUntil()` method in workflows, which pauses execution until a specified date.
- [Reference: Step Class | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/step): Documentation for the Step class in Mastra, which defines individual units of work within a workflow.
- [Reference: Workflow.then() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/then): Documentation for the `Workflow.then()` method in workflows, which creates sequential dependencies between steps.
- [Reference: Workflow.waitForEvent() | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/waitForEvent): Documentation for the `Workflow.waitForEvent()` method in workflows, which pauses execution until an event is received.
- [Reference: Workflow Class | Workflows | Mastra Docs](https://mastra.ai/en/reference/workflows/workflow): Documentation for the `Workflow` class in Mastra, which enables you to create state machines for complex sequences of operations with conditional branching and data validation.

## EN - showcase
- [Showcase](https://mastra.ai/en/showcase): Check out these applications built with Mastra

## JA - docs
- [ |  | Mastra](https://mastra.ai/ja/docs/agents/adding-tools): 
- [adding-voice](https://mastra.ai/ja/docs/agents/adding-voice)
- [ |  | Mastra ](https://mastra.ai/ja/docs/agents/agent-memory): Mastra
- [](https://mastra.ai/ja/docs/agents/dynamic-agents): 
- [Input Processors](https://mastra.ai/ja/docs/agents/input-processors): input processors
- [MCPMastra |  | Mastra](https://mastra.ai/ja/docs/agents/mcp-guide): MastraMCPAI
- [](https://mastra.ai/ja/docs/agents/output-processors):  AI 
- [ |  | Mastra](https://mastra.ai/ja/docs/agents/overview): Mastra
- [ | Agents | Mastra Docs](https://mastra.ai/ja/docs/agents/runtime-variables): Mastra
- [ |  | Mastra ](https://mastra.ai/ja/docs/agents/using-tools-and-mcp): MastraMCP
- [Auth](https://mastra.ai/ja/docs/auth): MastraAuth 
- [MastraJwtAuth](https://mastra.ai/ja/docs/auth/jwt): JSON Web TokenMastraMastraJwtAuth
- [](https://mastra.ai/ja/docs/community/contributing-templates): Mastra
- [Discord  |  | Mastra](https://mastra.ai/ja/docs/community/discord): Mastra Discord  MCP 
- [](https://mastra.ai/ja/docs/community/licensing): Mastra
- [MastraClient](https://mastra.ai/ja/docs/deployment/client): Mastra Client SDK
- [Amazon EC2](https://mastra.ai/ja/docs/deployment/cloud-providers/amazon-ec2): MastraAmazon EC2
- [AWS Lambda](https://mastra.ai/ja/docs/deployment/cloud-providers/aws-lambda): DockerAWS Lambda Web AdapterMastraAWS Lambda
- [Azure App Services](https://mastra.ai/ja/docs/deployment/cloud-providers/azure-app-services): MastraAzure App Services
- [Digital Ocean](https://mastra.ai/ja/docs/deployment/cloud-providers/digital-ocean): Mastra  DigitalOcean 
- [](https://mastra.ai/ja/docs/deployment/cloud-providers): Mastra
- [API](https://mastra.ai/ja/docs/deployment/custom-api-routes): MastraHTTP
- [](https://mastra.ai/ja/docs/deployment/deployment): HTTPMastra
- [](https://mastra.ai/ja/docs/deployment/middleware): 
- [](https://mastra.ai/ja/docs/deployment/monorepo):  Mastra 
- [](https://mastra.ai/ja/docs/deployment/overview): Mastra
- [Mastra ](https://mastra.ai/ja/docs/deployment/server-deployment): Mastra 
- [Mastra](https://mastra.ai/ja/docs/deployment/server): Mastra
- [Cloudflare Deployer](https://mastra.ai/ja/docs/deployment/serverless-platforms/cloudflare-deployer): Mastra CloudflareDeployerMastraCloudflare
- [](https://mastra.ai/ja/docs/deployment/serverless-platforms): HTTPMastra
- [Netlify Deployer](https://mastra.ai/ja/docs/deployment/serverless-platforms/netlify-deployer): Mastra NetlifyDeployerMastraNetlify
- [Vercel Deployer](https://mastra.ai/ja/docs/deployment/serverless-platforms/vercel-deployer): Mastra VercelDeployerMastraVercel
- [WebMastra](https://mastra.ai/ja/docs/deployment/web-framework): WebMastra
- [eval](https://mastra.ai/ja/docs/evals/custom-eval): Mastraeval
- [](https://mastra.ai/ja/docs/evals/overview): Mastra evalsAI
- [CI](https://mastra.ai/ja/docs/evals/running-in-ci): CI/CDMastra evals
- [](https://mastra.ai/ja/docs/evals/textual-evals): MastraLLM-as-judge
- [](https://mastra.ai/ja/docs/faq): Mastra 
- [Vercel AI SDK ](https://mastra.ai/ja/docs/frameworks/agentic-uis/ai-sdk): Mastra  Vercel AI SDK  Mastra 
- [Assistant UI](https://mastra.ai/ja/docs/frameworks/agentic-uis/assistant-ui): Assistant UIMastra
- [CopilotKit](https://mastra.ai/ja/docs/frameworks/agentic-uis/copilotkit): MastraCopilotKitAGUI
- [OpenRouter](https://mastra.ai/ja/docs/frameworks/agentic-uis/openrouter): OpenRouterMastra
- [Vercel AI SDK](https://mastra.ai/ja/docs/frameworks/ai-sdk): MastraVercel AI SDKMastra
- [CopilotKit](https://mastra.ai/ja/docs/frameworks/copilotkit): MastraCopilotKitAGUI
- [Mastra  NextJS  | Mastra ](https://mastra.ai/ja/docs/frameworks/next-js): Mastra  NextJS 
- [Mastra  Express  | Mastra ](https://mastra.ai/ja/docs/frameworks/servers/express): Mastra  Express 
- [Mastra  Astro  | Mastra ](https://mastra.ai/ja/docs/frameworks/web-frameworks/astro): Mastra  Astro 
- [Mastra  Next.js  | Mastra ](https://mastra.ai/ja/docs/frameworks/web-frameworks/next-js): Mastra  Next.js 
- [Mastra  SvelteKit  | Mastra ](https://mastra.ai/ja/docs/frameworks/web-frameworks/sveltekit): Mastra  SvelteKit 
- [Mastra  Vite/React  | Mastra ](https://mastra.ai/ja/docs/frameworks/web-frameworks/vite-react): Mastra  Vite  React 
- [Mastra |  | Mastra Docs](https://mastra.ai/ja/docs/getting-started/installation): MastraLLM
- [Cursor/Windsurf |  | Mastra ](https://mastra.ai/ja/docs/getting-started/mcp-docs-server): IDEMastra MCPMastra
- [model-capability](https://mastra.ai/ja/docs/getting-started/model-capability)
- [ |  | Mastra Docs](https://mastra.ai/ja/docs/getting-started/model-providers): Mastra
- [ |  | Mastra ](https://mastra.ai/ja/docs/getting-started/project-structure): Mastra
- [ |  | Mastra Docs](https://mastra.ai/ja/docs/getting-started/templates): Mastra
- [ | Mastra ](https://mastra.ai/ja/docs): MastraTypeScriptAIRAG
- [Mastra  | Mastra ](https://mastra.ai/ja/docs/integrations): APIMastra
- [ | Mastra](https://mastra.ai/ja/docs/local-dev/add-to-existing-project): Node.jsMastra
- [ | Mastra ](https://mastra.ai/ja/docs/local-dev/creating-a-new-project): CLI  Mastra  Node.js  Mastra 
- [`mastra dev` | Mastra ](https://mastra.ai/ja/docs/local-dev/mastra-dev): MastraMastra
- [Mastra Cloud](https://mastra.ai/ja/docs/mastra-cloud/dashboard): Mastra Cloud
- [Mastra Cloud](https://mastra.ai/ja/docs/mastra-cloud/deploying): MastraGitHub
- [Mastra Cloud](https://mastra.ai/ja/docs/mastra-cloud/observability): Mastra Cloud
- [Mastra Cloud](https://mastra.ai/ja/docs/mastra-cloud/overview): Mastra
- [](https://mastra.ai/ja/docs/mastra-cloud/setting-up): Mastra Cloud
- [memory-processors](https://mastra.ai/ja/docs/memory/memory-processors)
- [overview](https://mastra.ai/ja/docs/memory/overview)
- [semantic-recall](https://mastra.ai/ja/docs/memory/semantic-recall)
- [working-memory](https://mastra.ai/ja/docs/memory/working-memory)
- [complex-task-execution](https://mastra.ai/ja/docs/networks-vnext/complex-task-execution)
- [LLM | Networks | Mastra](https://mastra.ai/ja/docs/networks-vnext/overview): MastraNetworksAPIMastra
- [single-task-execution](https://mastra.ai/ja/docs/networks-vnext/single-task-execution)
- [ | Mastra ](https://mastra.ai/ja/docs/observability/logging): MastraAI
- [Next.js  | Mastra Observability ](https://mastra.ai/ja/docs/observability/nextjs-tracing): Next.js  OpenTelemetry 
- [ | Mastra ](https://mastra.ai/ja/docs/observability/tracing): MastraOpenTelemetry
- [ | RAG | Mastra ](https://mastra.ai/ja/docs/rag/chunking-and-embedding): Mastra
- [MastraRAG | Mastra](https://mastra.ai/ja/docs/rag/overview): MastraRAGLLM
- [ | RAG | Mastra ](https://mastra.ai/ja/docs/rag/retrieval): Mastra RAG
- [ | Mastra Docs](https://mastra.ai/ja/docs/rag/vector-databases): Mastra
- [custom-scorers](https://mastra.ai/ja/docs/scorers/custom-scorers)
- [](https://mastra.ai/ja/docs/scorers/off-the-shelf-scorers): AIMastra
- [](https://mastra.ai/ja/docs/scorers/overview): MastraAI
- [API](https://mastra.ai/ja/docs/server-db/custom-api-routes): MastraHTTP
- [mastra dev  | Mastra ](https://mastra.ai/ja/docs/server-db/local-dev-playground): Mastra 
- [MastraClient](https://mastra.ai/ja/docs/server-db/mastra-client): Mastra Client SDK
- [Middleware](https://mastra.ai/ja/docs/server-db/middleware): 
- [Mastra](https://mastra.ai/ja/docs/server-db/production-server): APICORSMastra
- [ |  | Mastra ](https://mastra.ai/ja/docs/server-db/snapshots): Mastra   
- [Mastra  | Mastra ](https://mastra.ai/ja/docs/server-db/storage): Mastra 
- [Mastra | Mastra](https://mastra.ai/ja/docs/storage/overview): Mastra
- [Streaming Events | Streaming | Mastra](https://mastra.ai/ja/docs/streaming/events): Mastra 
- [ | Streaming | Mastra](https://mastra.ai/ja/docs/streaming/overview): Mastra AI 
- [ |  | Mastra](https://mastra.ai/ja/docs/streaming/tool-streaming): Mastra 
- [  | Streaming | Mastra](https://mastra.ai/ja/docs/streaming/workflow-streaming): Mastra  
- [ |  & MCP | Mastra ](https://mastra.ai/ja/docs/tools-mcp/advanced-usage): Vercel AI SDKMastra
- [ |  & MCP | Mastra ](https://mastra.ai/ja/docs/tools-mcp/dynamic-context): Mastra RuntimeContext
- [MCP  | Tools & MCP | Mastra Docs](https://mastra.ai/ja/docs/tools-mcp/mcp-overview): Model Context ProtocolMCPMCPClient  MCPServer 
- [ |  & MCP | Mastra ](https://mastra.ai/ja/docs/tools-mcp/overview): Mastra
- [Mastra  | Mastra Docs](https://mastra.ai/ja/docs/voice/overview): Mastra 
- [Mastra | Mastra ](https://mastra.ai/ja/docs/voice/speech-to-speech): Mastra
- [Mastra STT | Mastra ](https://mastra.ai/ja/docs/voice/speech-to-text): Mastra 
- [Mastra TTS | Mastra ](https://mastra.ai/ja/docs/voice/text-to-speech): Mastra 
- [ | Workflows | Mastra Docs](https://mastra.ai/ja/docs/workflows/control-flow): Mastra 
- [ | Mastra ](https://mastra.ai/ja/docs/workflows/dynamic-workflows): 
- [ | Workflows | Mastra Docs](https://mastra.ai/ja/docs/workflows/error-handling): Mastra 
- [Inngest Workflows | Workflows | Mastra Docs](https://mastra.ai/ja/docs/workflows/inngest-workflow): Inngest workflowMastra workflowInngest
- [ | Mastra ](https://mastra.ai/ja/docs/workflows/input-data-mapping): Mastra
- [nested-workflows](https://mastra.ai/ja/docs/workflows/nested-workflows)
- [LLM |  | Mastra](https://mastra.ai/ja/docs/workflows/overview): Mastra
- [ | Mastra Docs](https://mastra.ai/ja/docs/workflows/pausing-execution): Mastra.sleep().sleepUntil().waitForEvent()
- [ -  |  | Mastra ](https://mastra.ai/ja/docs/workflows/runtime-variables): Mastra
- [ | Mastra ](https://mastra.ai/ja/docs/workflows/steps): Mastra
- [ |  | Mastra ](https://mastra.ai/ja/docs/workflows/suspend-and-resume): Mastra 
- [ |  | Mastra ](https://mastra.ai/ja/docs/workflows/using-with-agents-and-tools): Mastra 
- [ | Mastra ](https://mastra.ai/ja/docs/workflows/variables): Mastra
- [ |  | Mastra ](https://mastra.ai/ja/docs/workflows-legacy/control-flow): Mastra
- [ | Mastra ](https://mastra.ai/ja/docs/workflows-legacy/dynamic-workflows): 
- [ | Mastra ](https://mastra.ai/ja/docs/workflows-legacy/error-handling): Mastra
- [nested-workflows](https://mastra.ai/ja/docs/workflows-legacy/nested-workflows)
- [LLM |  | Mastra](https://mastra.ai/ja/docs/workflows-legacy/overview): Mastra
- [ -  | Workflows | Mastra ](https://mastra.ai/ja/docs/workflows-legacy/runtime-variables): Mastra 
- [ | Mastra ](https://mastra.ai/ja/docs/workflows-legacy/steps): Mastra 
- [ | Human-in-the-Loop | Mastra ](https://mastra.ai/ja/docs/workflows-legacy/suspend-and-resume): Mastra 
- [ | Mastra ](https://mastra.ai/ja/docs/workflows-legacy/variables): Mastra 
- [ |  (vNext) | Mastra ](https://mastra.ai/ja/docs/workflows-vnext/flow-control): Mastra (vNext) 
- [Inngest  |  (vNext) | Mastra ](https://mastra.ai/ja/docs/workflows-vnext/inngest-workflow): Inngest Inngest  Mastra vNext 
- [vNext | Mastra Docs](https://mastra.ai/ja/docs/workflows-vnext/input-data-mapping): MastravNext
- [LLM | vNext | Mastra](https://mastra.ai/ja/docs/workflows-vnext/overview): MastravNext
- [ (vNext) |  | Mastra ](https://mastra.ai/ja/docs/workflows-vnext/suspend-and-resume): Mastra vNext
- [ |  (vNext) | Mastra ](https://mastra.ai/ja/docs/workflows-vnext/using-with-agents-and-tools): MastravNext

## JA - examples
- [:  | Agents | Mastra](https://mastra.ai/ja/examples/agents/adding-voice-capabilities): Mastra 
- [ |  | Mastra ](https://mastra.ai/ja/examples/agents/agentic-workflows): MastraLLMAPI
- [: AI SDK v5  |  | Mastra ](https://mastra.ai/ja/examples/agents/ai-sdk-v5-integration): Mastra  AI SDK v5 
- [ |  | Mastra ](https://mastra.ai/ja/examples/agents/bird-checker): UnsplashMastra AI
- [ | Agents | Mastra Docs](https://mastra.ai/ja/examples/agents/calling-agents): 
- [: MCPServer  | Agents | Mastra ](https://mastra.ai/ja/examples/agents/deploying-mcp-server): stdio  Mastra MCPServer NPM 
- [ |  | Mastra ](https://mastra.ai/ja/examples/agents/dynamic-agents): Mastra 
- [:  |  | Mastra](https://mastra.ai/ja/examples/agents/hierarchical-multi-agent): Mastra
- [ | Agents | Mastra Docs](https://mastra.ai/ja/examples/agents/image-analysis): UnsplashMastraAI
- [:  | Agents | Mastra ](https://mastra.ai/ja/examples/agents/multi-agent-workflow): Mastra 
- [:  |  | Mastra](https://mastra.ai/ja/examples/agents/supervisor-agent): Mastra 
- [:  | Agents | Mastra Docs](https://mastra.ai/ja/examples/agents/system-prompt): MastraAI
- [ | Agents | Mastra Docs](https://mastra.ai/ja/examples/agents/using-a-tool): Mastra  AI 
- [:  | Agents | Mastra Docs](https://mastra.ai/ja/examples/agents/using-a-workflow): MastraAI
- [](https://mastra.ai/ja/examples/deployment/auth-middleware)
- [CORS ](https://mastra.ai/ja/examples/deployment/cors-middleware)
- [API](https://mastra.ai/ja/examples/deployment/custom-api-route)
- [Mastra ](https://mastra.ai/ja/examples/deployment/deploying-mastra-server)
- [](https://mastra.ai/ja/examples/deployment)
- [](https://mastra.ai/ja/examples/deployment/logging-middleware)
- [: Answer Relevancy | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/answer-relevancy): Answer Relevancy 
- [: Bias | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/bias): Bias
- [: Completeness | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/completeness):  Completeness 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/content-similarity):  Content Similarity 
- [: Context Position | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/context-position):  Context Position 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/context-precision): Context Precision
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/context-relevancy): Context Relevancy 
- [Contextual Recall | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/contextual-recall): Contextual Recall 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/custom-eval): MastraLLM
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/custom-llm-judge-eval): LLM
- [:  | Evals | Mastra ](https://mastra.ai/ja/examples/evals/custom-native-javascript-eval):  JavaScript 
- [: Faithfulness | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/faithfulness): Faithfulness 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/hallucination): 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/keyword-coverage): Keyword Coverage 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/prompt-alignment): 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/summarization): LLM 
- [: Textual Difference | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/textual-difference):  Textual Difference 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/tone-consistency): Tone Consistency 
- [: Toxicity | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/toxicity): Toxicity 
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/examples/evals/word-inclusion): 
- [WorkflowsAgentsRAG | Mastra ](https://mastra.ai/ja/examples): Mastra  AI RAG OpenAIAnthropicGoogle Gemini  AI 
- [](https://mastra.ai/ja/examples/memory/memory-processors): 
- [memory-with-libsql](https://mastra.ai/ja/examples/memory/memory-with-libsql)
- [memory-with-mem0](https://mastra.ai/ja/examples/memory/memory-with-mem0)
- [memory-with-pg](https://mastra.ai/ja/examples/memory/memory-with-pg)
- [memory-with-upstash](https://mastra.ai/ja/examples/memory/memory-with-upstash)
- [](https://mastra.ai/ja/examples/memory/streaming-working-memory-advanced): Todo
- [](https://mastra.ai/ja/examples/memory/streaming-working-memory-structured): ToDo
- [](https://mastra.ai/ja/examples/memory/streaming-working-memory): 
- [AI SDK useChat ](https://mastra.ai/ja/examples/memory/use-chat): Mastra  Vercel AI SDK useChat 
- [ | RAG | Mastra ](https://mastra.ai/ja/examples/rag/chunking/adjust-chunk-delimiters): Mastra
- [ | RAG | Mastra ](https://mastra.ai/ja/examples/rag/chunking/adjust-chunk-size): Mastra
- [HTML | RAG | Mastra ](https://mastra.ai/ja/examples/rag/chunking/chunk-html): MastraHTML
- [JSON | RAG | Mastra ](https://mastra.ai/ja/examples/rag/chunking/chunk-json): MastraJSON
- [ | RAG | Mastra ](https://mastra.ai/ja/examples/rag/chunking/chunk-markdown): Mastra
- [ | RAG | Mastra ](https://mastra.ai/ja/examples/rag/chunking/chunk-text): Mastra
- [:  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/embedding/embed-chunk-array): Mastra 
- [:  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/embedding/embed-text-chunk): Mastra 
- [: Cohere  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/embedding/embed-text-with-cohere): Mastra  Cohere 
- [:  |  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/embedding/metadata-extraction): Mastra 
- [:  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/query/hybrid-vector-search): PGVector Mastra 
- [: Top-K | RAG | Mastra ](https://mastra.ai/ja/examples/rag/query/retrieve-results): Mastra
- [:  |  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/rerank/rerank-rag): OpenAI  PGVector Mastra  RAG 
- [:  |  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/rerank/rerank): OpenAI  PGVector Mastra 
- [: Cohere | RAG | Mastra ](https://mastra.ai/ja/examples/rag/rerank/reranking-with-cohere): MastraCohere
- [: ZeroEntropy | RAG | Mastra Docs](https://mastra.ai/ja/examples/rag/rerank/reranking-with-zeroentropy): ZeroEntropyMastra
- [:  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/upsert/upsert-embeddings): Mastra 
- [:  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/usage/basic-rag): OpenAI  PGVector Mastra  RAG 
- [:  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/usage/cleanup-rag): LLMMastraRAG
- [: Chain of Thought  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/usage/cot-rag): OpenAI  PGVector Mastra  chain-of-thought  RAG 
- [:  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/usage/cot-workflow-rag): Mastra  RAG 
- [ | RAG | Mastra Examples](https://mastra.ai/ja/examples/rag/usage/database-specific-config): 
- [:  |  | RAG | Mastra ](https://mastra.ai/ja/examples/rag/usage/filter-rag): RAG  Mastra 
- [: RAG | RAG | Mastra ](https://mastra.ai/ja/examples/rag/usage/graph-rag): OpenAIPGVectorMastraRAG
- [: Answer Relevancy | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/answer-relevancy): Answer Relevancy
- [: Bias | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/bias): Bias
- [: Completeness | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/completeness): Completeness
- [:  | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/content-similarity): Content Similarity scorer
- [: Context Precision  | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/context-precision): Mean Average Precision RAG  Context Precision 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/scorers/context-relevance): 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/scorers/custom-scorer): createScorer
- [: Faithfulness | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/faithfulness): Faithfulness
- [: Hallucination | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/hallucination): Hallucination
- [:  | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/keyword-coverage): Keyword Coverage
- [: Textual Difference | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/textual-difference): Textual Difference
- [:  | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/tone-consistency): Tone Consistency scorer
- [:  |  | Mastra ](https://mastra.ai/ja/examples/scorers/tool-call-accuracy):  LLM 
- [: Toxicity | Scorers | Mastra Docs](https://mastra.ai/ja/examples/scorers/toxicity): Toxicity
- [ |  | Mastra Docs](https://mastra.ai/ja/examples/tools/calling-tools): 
- [ |  | Mastra ](https://mastra.ai/ja/examples/tools/dynamic-tools): Mastra
- [:  |  | Mastra ](https://mastra.ai/ja/examples/tools/workflow-as-tools): 
- [](https://mastra.ai/ja/examples/voice/speech-to-speech): Mastra 
- [:  | Voice | Mastra ](https://mastra.ai/ja/examples/voice/speech-to-text): Mastra 
- [:  | Voice | Mastra ](https://mastra.ai/ja/examples/voice/text-to-speech): Mastra 
- [](https://mastra.ai/ja/examples/voice/turn-taking): Mastra
- [:  | Workflows | Mastra Docs](https://mastra.ai/ja/examples/workflows/agent-as-step):  Mastra 
- [:  (.foreach()) | Workflows | Mastra Docs](https://mastra.ai/ja/examples/workflows/array-as-input):  .foreach()  Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows/branching-paths):  Mastra 
- [ | Mastra ](https://mastra.ai/ja/examples/workflows/calling-agent):  AI  Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows/conditional-branching):  `branch` Mastra 
- [ |  | Mastra ](https://mastra.ai/ja/examples/workflows/creating-a-workflow): Mastra
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows/cyclical-dependencies): Mastra 
- [: Human-in-the-Loop | Workflows | Mastra Docs](https://mastra.ai/ja/examples/workflows/human-in-the-loop-multi-turn): suspend/resume  doUntil Mastra 
- [Human in the Loop |  | Mastra ](https://mastra.ai/ja/examples/workflows/human-in-the-loop):  Mastra 
- [Inngest Workflow |  | Mastra ](https://mastra.ai/ja/examples/workflows/inngest-workflow): Mastra  Inngest 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows/parallel-steps):  Mastra 
- [ |  | Mastra Docs](https://mastra.ai/ja/examples/workflows/running-workflows): 
- [ | Workflows | Mastra Docs](https://mastra.ai/ja/examples/workflows/sequential-steps):  Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows/suspend-and-resume):  Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows/tool-as-step): Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows/using-a-tool-as-a-step): Mastra 
- [ | Mastra ](https://mastra.ai/ja/examples/workflows/workflow-variables): Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/branching-paths): Mastra
- [:  | Mastra Docs](https://mastra.ai/ja/examples/workflows_legacy/calling-agent): MastraAI
- [ |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/conditional-branching): Mastra  if/else 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/creating-a-workflow): Mastra 1
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/cyclical-dependencies): Mastra 
- [: Human in the Loop |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/human-in-the-loop): Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/parallel-steps):  Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/sequential-steps): Mastra 
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/suspend-and-resume):  Mastra 
- [ |  | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/using-a-tool-as-a-step): Mastra
- [ | Mastra ](https://mastra.ai/ja/examples/workflows_legacy/workflow-variables): Mastra 
- [: / |  | Mastra ](https://mastra.ai/ja/examples/workflows_vNext/agent-and-tool-interop): Mastra
- [:  (.foreach()) |  | Mastra ](https://mastra.ai/ja/examples/workflows_vNext/array-as-input): Mastra.foreach()
- [ | Mastra ](https://mastra.ai/ja/examples/workflows_vNext/calling-agent): AIMastra
- [ |  | Mastra ](https://mastra.ai/ja/examples/workflows_vNext/conditional-branching): Mastra`branch`
- [ |  | Mastra ](https://mastra.ai/ja/examples/workflows_vNext/control-flow): Mastra
- [ |  | Mastra ](https://mastra.ai/ja/examples/workflows_vNext/human-in-the-loop): Mastra
- [Inngest  |  | Mastra ](https://mastra.ai/ja/examples/workflows_vNext/inngest-workflow): Mastrainngest
- [:  |  | Mastra ](https://mastra.ai/ja/examples/workflows_vNext/parallel-steps): Mastra

## JA - guides
- [AI  | Mastra Workflows | ](https://mastra.ai/ja/guides/guide/ai-recruiter): Mastra LLM 
- [AI | Mastra Agent ](https://mastra.ai/ja/guides/guide/chef-michel): Mastra
- [MCP : Notes MCP  | Mastra ](https://mastra.ai/ja/guides/guide/notes-mcp-server): Mastra  MCPModel Context Protocol
- [ | Mastra RAG ](https://mastra.ai/ja/guides/guide/research-assistant): RAG  AI 
- [AI | Mastra Agents | ](https://mastra.ai/ja/guides/guide/stock-agent): Mastra
- [](https://mastra.ai/ja/guides): Mastra

## JA - reference
- [: Agent  | Agents | Mastra ](https://mastra.ai/ja/reference/agents/agent): Mastra  `Agent`  AI 
- [: createTool() |  |  | Mastra ](https://mastra.ai/ja/reference/agents/createTool): Mastra  createTool 
- [: Agent.generate() |  | Mastra ](https://mastra.ai/ja/reference/agents/generate): Mastra`Agent.generate()`
- [: Agent.getAgent() |  | Mastra ](https://mastra.ai/ja/reference/agents/getAgent): Mastra`Agent.getAgent()`
- [: Agent.getDefaultGenerateOptions() |  | Mastra ](https://mastra.ai/ja/reference/agents/getDefaultGenerateOptions): Mastra`Agent.getDefaultGenerateOptions()`generate
- [: Agent.getDefaultStreamOptions() |  | Mastra ](https://mastra.ai/ja/reference/agents/getDefaultStreamOptions): Mastra`Agent.getDefaultStreamOptions()`
- [: Agent.getDefaultVNextStreamOptions() | Agents | Mastra ](https://mastra.ai/ja/reference/agents/getDefaultVNextStreamOptions): Mastra  `Agent.getDefaultVNextStreamOptions()` streamVNext 
- [: Agent.getDescription() |  | Mastra ](https://mastra.ai/ja/reference/agents/getDescription): Mastra`Agent.getDescription()`
- [: Agent.getInstructions() |  | Mastra ](https://mastra.ai/ja/reference/agents/getInstructions): Mastra`Agent.getInstructions()`
- [: Agent.getLLM() |  | Mastra ](https://mastra.ai/ja/reference/agents/getLLM): Mastra`Agent.getLLM()`
- [: Agent.getMemory() |  | Mastra ](https://mastra.ai/ja/reference/agents/getMemory): Mastra`Agent.getMemory()`
- [: Agent.getModel() |  | Mastra ](https://mastra.ai/ja/reference/agents/getModel): Mastra`Agent.getModel()`
- [: Agent.getScorers() |  | Mastra ](https://mastra.ai/ja/reference/agents/getScorers): Mastra`Agent.getScorers()`
- [: Agent.getTools() |  | Mastra ](https://mastra.ai/ja/reference/agents/getTools): Mastra`Agent.getTools()`
- [: Agent.getVoice() |  | Mastra ](https://mastra.ai/ja/reference/agents/getVoice): Mastra`Agent.getVoice()`
- [: Agent.getWorkflows() |  | Mastra ](https://mastra.ai/ja/reference/agents/getWorkflows): Mastra`Agent.getWorkflows()`
- [: Agent.stream() |  | Mastra ](https://mastra.ai/ja/reference/agents/stream): Mastra`Agent.stream()`
- [: Agent.streamVNext() | Agents | Mastra Docs](https://mastra.ai/ja/reference/agents/streamVNext): Mastra  `Agent.streamVNext()` 
- [MastraJwtAuth](https://mastra.ai/ja/reference/auth/jwt): JSON Web TokenMastraMastraJwtAuthAPI
- [mastra build |  | Mastra CLI](https://mastra.ai/ja/reference/cli/build): Mastra 
- [create-mastra |  | Mastra CLI](https://mastra.ai/ja/reference/cli/create-mastra): create-mastraMastra
- [mastra dev |  | Mastra CLI](https://mastra.ai/ja/reference/cli/dev): mastra dev
- [mastra init |  | Mastra CLI](https://mastra.ai/ja/reference/cli/init): Mastramastra init
- [mastra lint |  | Mastra CLI](https://mastra.ai/ja/reference/cli/lint): Mastralint
- [@mastra/mcp-docs-server](https://mastra.ai/ja/reference/cli/mcp-docs-server): MCPMastra
- [mastra scorers |  | Mastra CLI](https://mastra.ai/ja/reference/cli/scorers): Mastra CLI  AI 
- [mastra start](https://mastra.ai/ja/reference/cli/start):  Mastra 
- [Mastra  API](https://mastra.ai/ja/reference/client-js/agents): Mastra AIclient-js SDK
- [Mastra](https://mastra.ai/ja/reference/client-js/error-handling): Mastra client-js SDK
- [Mastra  API](https://mastra.ai/ja/reference/client-js/logs): client-js SDKMastra
- [MastraClient](https://mastra.ai/ja/reference/client-js/mastra-client): client-js SDK  Mastra 
- [Mastra API](https://mastra.ai/ja/reference/client-js/memory): client-js SDKMastra
- [Mastra API](https://mastra.ai/ja/reference/client-js/telemetry): client-js SDKMastra
- [Mastra  API](https://mastra.ai/ja/reference/client-js/tools): client-js SDKMastra
- [Mastra  API](https://mastra.ai/ja/reference/client-js/vectors): client-js SDKMastra
- [Mastra API](https://mastra.ai/ja/reference/client-js/workflows-legacy): client-js SDKMastra
- [Mastra  (vNext) API](https://mastra.ai/ja/reference/client-js/workflows-vnext): client-js SDKMastravNext
- [Mastra API](https://mastra.ai/ja/reference/client-js/workflows): client-js SDKMastra
- [Mastra Core](https://mastra.ai/ja/reference/core/mastra-class): MCP  Mastra 
- [Cloudflare Deployer](https://mastra.ai/ja/reference/deployer/cloudflare): CloudflareDeployerMastraCloudflare Workers
- [Mastra Deployer](https://mastra.ai/ja/reference/deployer/deployer): MastraDeployer
- [Netlify Deployer](https://mastra.ai/ja/reference/deployer/netlify): NetlifyDeployerMastraNetlify Functions
- [Vercel ](https://mastra.ai/ja/reference/deployer/vercel): Mastra Vercel  VercelDeployer 
- [: Answer Relevancy |  | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/answer-relevancy): MastraAnswer RelevancyLLM
- [: Bias | Output Metrics | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/bias): MastraBiasLLM
- [: Completeness | Metrics | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/completeness): MastraLLM
- [: Content Similarity | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/content-similarity): MastraContent Similarity Metric
- [: Context Position | Metrics | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/context-position): MastraContext Position Metric
- [: Context Precision |  | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/context-precision): MastraContext Precision
- [: Context Relevancy | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/context-relevancy): RAGContext Relevancy
- [: Contextual Recall |  | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/contextual-recall): LLMContextual Recall
- [: Faithfulness | Metrics | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/faithfulness): MastraLLM
- [: Hallucination | Metrics | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/hallucination): MastraLLM
- [:  |  |  | Mastra ](https://mastra.ai/ja/reference/evals/keyword-coverage): LLMMastra
- [: Prompt Alignment | Metrics | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/prompt-alignment): MastraPrompt AlignmentLLM
- [:  |  |  | Mastra ](https://mastra.ai/ja/reference/evals/summarization): MastraLLM
- [:  | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/textual-difference): Mastra
- [:  |  | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/tone-consistency): Mastra
- [: Toxicity | Metrics | Evals | Mastra Docs](https://mastra.ai/ja/reference/evals/toxicity): MastraToxicity MetricLLM
- [API ](https://mastra.ai/ja/reference): Mastra API 
- [: .after() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/after):  `after()` 
- [.afterEvent()  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/afterEvent): Mastra  afterEvent 
- [: Workflow.commit() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/commit):  `.commit()` 
- [: Workflow.createRun() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/createRun):  `.createRun()` 
- [: Workflow.else() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/else): Mastra  `.else()` if 
- [ | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/events): MastraafterEventresumeWithEvent
- [: Workflow.execute() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/execute): Mastra  `.execute()` 
- [: Workflow.if() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/if): Mastra  `.if()` 
- [: run.resume() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/resume):  `.resume()` 
- [.resumeWithEvent()  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/resumeWithEvent):  resumeWithEvent 
- [:  |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/snapshots): Mastra  - 
- [: start() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/start):  `start()` 
- [: Step |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/step-class):  Step 
- [: StepCondition |  | Mastra](https://mastra.ai/ja/reference/legacyWorkflows/step-condition): 
- [: Workflow.step() | Workflows () | Mastra Docs](https://mastra.ai/ja/reference/legacyWorkflows/step-function):  `.step()` 
- [: StepOptions |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/step-options): 
- [ |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/step-retries): Mastra 
- [: suspend() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/suspend): Mastra  suspend 
- [: Workflow.then() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/then):  `.then()` 
- [: Workflow.until() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/until): Mastra  `.until()` 
- [: run.watch() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/watch):  `.watch()` 
- [: Workflow.while() |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/while): Mastra  `.while()` 
- [: Workflow  |  | Mastra ](https://mastra.ai/ja/reference/legacyWorkflows/workflow): Mastra  Workflow 
- [Memory](https://mastra.ai/ja/reference/memory/Memory)
- [createThread](https://mastra.ai/ja/reference/memory/createThread)
- [deleteMessages](https://mastra.ai/ja/reference/memory/deleteMessages)
- [getThreadById](https://mastra.ai/ja/reference/memory/getThreadById)
- [getThreadsByResourceId](https://mastra.ai/ja/reference/memory/getThreadsByResourceId)
- [getThreadsByResourceIdPaginated](https://mastra.ai/ja/reference/memory/getThreadsByResourceIdPaginated)
- [query](https://mastra.ai/ja/reference/memory/query)
- [AgentNetwork](https://mastra.ai/ja/reference/networks/agent-network): AgentNetwork
- [: PinoLogger | Mastra Observability Docs](https://mastra.ai/ja/reference/observability/logger): PinoLogger
- [: OtelConfig | Mastra Observability ](https://mastra.ai/ja/reference/observability/otel-config): OpenTelemetry  OtelConfig 
- [: Braintrust |  | Mastra ](https://mastra.ai/ja/reference/observability/providers/braintrust): BraintrustMastraMastraLLM
- [: Dash0 | Mastra](https://mastra.ai/ja/reference/observability/providers/dash0): MastraOpen TelemetryDash0
- [:  |  | Mastra ](https://mastra.ai/ja/reference/observability/providers): Mastra Dash0SigNozBraintrustLangfuse 
- [: Keywords AI | Mastra Observability ](https://mastra.ai/ja/reference/observability/providers/keywordsai): Keywords AILLMMastra
- [: Laminar  | Mastra ](https://mastra.ai/ja/reference/observability/providers/laminar): LLMMastraLaminar
- [: Langfuse | Mastra](https://mastra.ai/ja/reference/observability/providers/langfuse): LLMMastraLangfuse
- [: LangSmith  | Mastra  ](https://mastra.ai/ja/reference/observability/providers/langsmith): LLMMastraLangSmith
- [: LangWatch | Mastra](https://mastra.ai/ja/reference/observability/providers/langwatch): LLMLangWatchMastra
- [: New Relic  | Mastra  ](https://mastra.ai/ja/reference/observability/providers/new-relic): New Relic  Mastra Mastra OpenTelemetry  
- [: SigNoz  | Mastra  ](https://mastra.ai/ja/reference/observability/providers/signoz): SigNozMastraMastraOpenTelemetryAPM
- [: Traceloop  | Mastra ](https://mastra.ai/ja/reference/observability/providers/traceloop): Traceloop  Mastra Mastra  LLM  OpenTelemetry 
- [: Astra  |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/astra): MastraAstraVectorDataStax Astra DB
- [: Chroma Vector Store |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/chroma): Mastra  ChromaVector ChromaDB 
- [: .chunk() |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/chunk): Mastra  chunk 
- [: Couchbase Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/ja/reference/rag/couchbase): Couchbase Vector SearchMastraCouchbaseVector
- [: DatabaseConfig | RAG | Mastra Docs](https://mastra.ai/ja/reference/rag/database-config): MastraRAGAPI
- [: MDocument |  | RAG | Mastra Docs](https://mastra.ai/ja/reference/rag/document): MastraMDocument
- [: embed() |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/embeddings): MastraAI SDK
- [: ExtractParams |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/extract-params): Mastra
- [: GraphRAG | RAG | RAG | Mastra ](https://mastra.ai/ja/reference/rag/graph-rag): MastraGraphRAG
- [: Lance Vector Store | Vector Databases | RAG | Mastra Docs](https://mastra.ai/ja/reference/rag/lance): MastraLanceVectorStoreLanceLanceDB
- [ |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/libsql): MastraLibSQLLibSQLVector
- [:  |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/metadata-filters): Mastra 
- [: MongoDB  |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/mongodb): Mastra  MongoDBVector MongoDB Atlas  Atlas Vector Search 
- [: OpenSearch  |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/opensearch): Mastra OpenSearchVector OpenSearch
- [: PG Vector Store |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/pg): Mastra  PgVector pgvector  PostgreSQL 
- [: Pinecone Vector Store |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/pinecone): Mastra  PineconeVector Pinecone 
- [: Qdrant  |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/qdrant): MastraQdrantQdrant
- [: Rerank |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/rerank): Mastra  rerank 
- [: Rerank |  | RAG | Mastra Docs](https://mastra.ai/ja/reference/rag/rerankWithScorer): Mastrarerank
- [: Turbopuffer  |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/turbopuffer): TurbopufferMastra
- [: Upstash |  | RAG | Mastra](https://mastra.ai/ja/reference/rag/upstash): MastraUpstash VectorUpstashVector
- [: Cloudflare  |  | RAG | Mastra ](https://mastra.ai/ja/reference/rag/vectorize): Mastra CloudflareVectorCloudflare Vectorize
- [: Answer Relevancy | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/answer-relevancy): LLMMastraAnswer Relevancy Scorer
- [: Bias | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/bias): MastraBias ScorerLLM
- [: Completeness | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/completeness): Mastra Completeness Scorer LLM
- [: Content Similarity | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/content-similarity): Mastra
- [: Context Precision Scorer | Scorers | Mastra ](https://mastra.ai/ja/reference/scorers/context-precision): Mastra  Context Precision Scorer Mean Average Precision
- [:  | Scorers | Mastra ](https://mastra.ai/ja/reference/scorers/context-relevance): Mastra  Context Relevance Scorer 
- [:  |  | Mastra ](https://mastra.ai/ja/reference/scorers/create-scorer): Mastra  JavaScript  LLM 
- [: Faithfulness | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/faithfulness): Mastra Faithfulness Scorer LLM
- [: Hallucination | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/hallucination): MastraLLM
- [:  |  | Mastra Docs](https://mastra.ai/ja/reference/scorers/keyword-coverage): LLMMastra
- [: MastraScorer | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/mastra-scorer): MastraMastraScorer
- [: Textual Difference | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/textual-difference): Mastra
- [:  |  | Mastra Docs](https://mastra.ai/ja/reference/scorers/tone-consistency): Mastra
- [:  |  | Mastra ](https://mastra.ai/ja/reference/scorers/tool-call-accuracy): Mastra LLM 
- [: Toxicity | Scorers | Mastra Docs](https://mastra.ai/ja/reference/scorers/toxicity): MastraLLM
- [Cloudflare D1  |  | Mastra Core](https://mastra.ai/ja/reference/storage/cloudflare-d1): Mastra  Cloudflare D1 SQL 
- [Cloudflare Storage |  | Mastra Core](https://mastra.ai/ja/reference/storage/cloudflare): MastraCloudflare KV
- [DynamoDB  |  | Mastra Core](https://mastra.ai/ja/reference/storage/dynamodb): ElectroDBMastraDynamoDB
- [LanceDB Storage](https://mastra.ai/ja/reference/storage/lance): MastraLanceDB
- [LibSQL  |  | Mastra Core](https://mastra.ai/ja/reference/storage/libsql): Mastra LibSQL 
- [MSSQL Storage | Storage System | Mastra Core](https://mastra.ai/ja/reference/storage/mssql): MastraMSSQL
- [PostgreSQL |  | Mastra Core](https://mastra.ai/ja/reference/storage/postgresql): MastraPostgreSQL
- [Upstash Storage | Storage System | Mastra Core](https://mastra.ai/ja/reference/storage/upstash): MastraUpstash
- [](https://mastra.ai/ja/reference/templates): Mastra 
- [: MastraMCPClient |  | Mastra ](https://mastra.ai/ja/reference/tools/client): MastraMCPClient  API  - Model Context Protocol 
- [: createTool() |  | Mastra ](https://mastra.ai/ja/reference/tools/create-tool): Mastra `createTool()`
- [: createDocumentChunkerTool() |  | Mastra ](https://mastra.ai/ja/reference/tools/document-chunker-tool): Mastra  Document Chunker Tool 
- [: createGraphRAGTool() | RAG | Mastra Tools ](https://mastra.ai/ja/reference/tools/graph-rag-tool): Mastra  Graph RAG  RAG 
- [: MCPClient |  | Mastra ](https://mastra.ai/ja/reference/tools/mcp-client): MCPClientAPI - Model Context Protocol
- [: MCPClient |  | Mastra ](https://mastra.ai/ja/reference/tools/mcp-configuration): MCPClient  API  - 
- [: MCPServer | MCPMastra | Mastra Docs](https://mastra.ai/ja/reference/tools/mcp-server): MCPServer API - MastraCapabilityModel Context Protocol
- [: createVectorQueryTool() | RAG | Mastra Tools ](https://mastra.ai/ja/reference/tools/vector-query-tool):  Mastra  Vector Query Tool 
- [: Azure Voice |  | Mastra ](https://mastra.ai/ja/reference/voice/azure): Azure Cognitive Services  AzureVoice 
- [: Cloudflare Voice |  | Mastra ](https://mastra.ai/ja/reference/voice/cloudflare): CloudflareVoice Cloudflare Workers AI 
- [: CompositeVoice | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/composite-voice): CompositeVoice 
- [: Deepgram Voice |  | Mastra ](https://mastra.ai/ja/reference/voice/deepgram): Deepgram voice 
- [: ElevenLabs Voice | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/elevenlabs): ElevenLabs
- [: Google Gemini Live Voice |  | Mastra ](https://mastra.ai/ja/reference/voice/google-gemini-live): GeminiLiveVoice Google  Gemini Live API Gemini API  Vertex AI 
- [: Google Voice |  | Mastra ](https://mastra.ai/ja/reference/voice/google): Google Voice 
- [: MastraVoice | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/mastra-voice): Mastra  MastraVoice 
- [: Murf Voice | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/murf): Murf voice 
- [: OpenAI Realtime Voice | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/openai-realtime): OpenAIRealtimeVoice WebSocket 
- [: OpenAI Voice |  | Mastra ](https://mastra.ai/ja/reference/voice/openai): OpenAIVoice
- [: PlayAI Voice | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/playai): PlayAI voice 
- [: Sarvam Voice | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/sarvam): Sarvam
- [: Speechify Voice | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/speechify): Speechify voice 
- [: voice.addInstructions() |  | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.addInstructions): addInstructions()
- [: voice.addTools() | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/voice.addTools): voice  addTools() 
- [: voice.answer() | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/voice.answer):  answer() 
- [: voice.close() | Voice Providers | Mastra ](https://mastra.ai/ja/reference/voice/voice.close): voice  close() 
- [: voice.connect() |  | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.connect): connect()
- [ |  | Mastra ](https://mastra.ai/ja/reference/voice/voice.events): 
- [: voice.getSpeakers() |  | Mastra ](https://mastra.ai/ja/reference/voice/voice.getSpeakers): getSpeakers()
- [: voice.listen() |  | Mastra ](https://mastra.ai/ja/reference/voice/voice.listen): Mastralisten()
- [: voice.off() |  | Mastra ](https://mastra.ai/ja/reference/voice/voice.off): off()
- [: voice.on() |  | Mastra ](https://mastra.ai/ja/reference/voice/voice.on): on()
- [: voice.send() |  | Mastra ](https://mastra.ai/ja/reference/voice/voice.send): send()
- [: voice.speak() |  | Mastra ](https://mastra.ai/ja/reference/voice/voice.speak): Mastraspeak()
- [: voice.updateConfig() | Voice Providers | Mastra Docs](https://mastra.ai/ja/reference/voice/voice.updateConfig): voiceupdateConfig()voice
- [: .after() |  | Mastra ](https://mastra.ai/ja/reference/workflows/after):  `after()` 
- [.afterEvent()  | Mastra ](https://mastra.ai/ja/reference/workflows/afterEvent): MastraafterEvent
- [: Workflow.branch() |  | Mastra ](https://mastra.ai/ja/reference/workflows/branch): `Workflow.branch()`
- [: Workflow.commit() |  | Mastra ](https://mastra.ai/ja/reference/workflows/commit):  `Workflow.commit()` 
- [: Workflow.createRunAsync() | Workflows | Mastra Docs](https://mastra.ai/ja/reference/workflows/create-run):  `Workflow.createRunAsync()` 
- [: Workflow.createRun() |  | Mastra Docs](https://mastra.ai/ja/reference/workflows/createRun):  `.createRun()` 
- [: Workflow.dountil() |  | Mastra ](https://mastra.ai/ja/reference/workflows/dountil): `Workflow.dountil()`
- [: Workflow.dowhile() |  | Mastra ](https://mastra.ai/ja/reference/workflows/dowhile): `Workflow.dowhile()`
- [: Workflow.else() |  | Mastra ](https://mastra.ai/ja/reference/workflows/else): Mastra`.else()`iffalse
- [ | Mastra ](https://mastra.ai/ja/reference/workflows/events): MastraafterEventresumeWithEvent
- [: Workflow.execute() |  | Mastra ](https://mastra.ai/ja/reference/workflows/execute):  `Workflow.execute()` 
- [: Workflow.foreach() |  | Mastra ](https://mastra.ai/ja/reference/workflows/foreach):  `Workflow.foreach()` 
- [: Workflow.if() |  | Mastra ](https://mastra.ai/ja/reference/workflows/if): Mastra`.if()`
- [: Workflow.map() |  | Mastra ](https://mastra.ai/ja/reference/workflows/map): `Workflow.map()`
- [: Workflow.parallel() |  | Mastra ](https://mastra.ai/ja/reference/workflows/parallel): `Workflow.parallel()`
- [: run.resume() |  | Mastra ](https://mastra.ai/ja/reference/workflows/resume): `.resume()`
- [.resumeWithEvent()  | Mastra ](https://mastra.ai/ja/reference/workflows/resumeWithEvent):  resumeWithEvent 
- [: Run.cancel() | Workflows | Mastra Docs](https://mastra.ai/ja/reference/workflows/run-methods/cancel):  `Run.cancel()` 
- [: Run.resume() | Workflows | Mastra ](https://mastra.ai/ja/reference/workflows/run-methods/resume):  `Run.resume()` 
- [: Run.start() | Workflows | Mastra Docs](https://mastra.ai/ja/reference/workflows/run-methods/start):  `Run.start()` 
- [: Run.stream() | Workflows | Mastra ](https://mastra.ai/ja/reference/workflows/run-methods/stream):  `Run.stream()` 
- [: Run.streamVNext() | Workflows | Mastra Docs](https://mastra.ai/ja/reference/workflows/run-methods/streamVNext):  `Run.streamVNext()` 
- [: Run.watch() | Workflows | Mastra ](https://mastra.ai/ja/reference/workflows/run-methods/watch):  `Run.watch()` 
- [: Run  | Workflows | Mastra ](https://mastra.ai/ja/reference/workflows/run): Mastra  Run 
- [: Workflow.sendEvent() |  | Mastra ](https://mastra.ai/ja/reference/workflows/sendEvent): `Workflow.sendEvent()`
- [: Workflow.sleep() |  | Mastra ](https://mastra.ai/ja/reference/workflows/sleep): `Workflow.sleep()`
- [: Workflow.sleepUntil() |  | Mastra ](https://mastra.ai/ja/reference/workflows/sleepUntil): `Workflow.sleepUntil()`
- [:  |  | Mastra ](https://mastra.ai/ja/reference/workflows/snapshots): Mastra - 
- [: start() |  | Mastra ](https://mastra.ai/ja/reference/workflows/start): `start()`
- [:  |  | Mastra ](https://mastra.ai/ja/reference/workflows/step-class): 
- [: StepCondition |  | Mastra](https://mastra.ai/ja/reference/workflows/step-condition): 
- [: Workflow.step() |  | Mastra ](https://mastra.ai/ja/reference/workflows/step-function): `.step()`
- [: StepOptions |  | Mastra ](https://mastra.ai/ja/reference/workflows/step-options): 
- [ |  | Mastra ](https://mastra.ai/ja/reference/workflows/step-retries): Mastra
- [: Step  |  | Mastra ](https://mastra.ai/ja/reference/workflows/step): MastraStep
- [: suspend() |  | Mastra ](https://mastra.ai/ja/reference/workflows/suspend): Mastrasuspend
- [: Workflow.then() |  | Mastra ](https://mastra.ai/ja/reference/workflows/then): `Workflow.then()`
- [: Workflow.until() |  | Mastra ](https://mastra.ai/ja/reference/workflows/until): Mastra  `.until()` 
- [: Workflow.waitForEvent() |  | Mastra ](https://mastra.ai/ja/reference/workflows/waitForEvent): `Workflow.waitForEvent()`
- [: run.watch() |  | Mastra ](https://mastra.ai/ja/reference/workflows/watch):  `.watch()` 
- [: Workflow.while() |  | Mastra ](https://mastra.ai/ja/reference/workflows/while): Mastra  `.while()` 
- [: Workflow | Workflows | Mastra Docs](https://mastra.ai/ja/reference/workflows/workflow): Mastra`Workflow`

## JA - showcase
- [](https://mastra.ai/ja/showcase): Mastra